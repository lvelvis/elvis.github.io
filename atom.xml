<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://lvelvis.github.io</id>
    <title>lvelvis</title>
    <updated>2020-06-22T06:54:02.397Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="http://lvelvis.github.io"/>
    <link rel="self" href="http://lvelvis.github.io/atom.xml"/>
    <subtitle>时光,浓淡相宜;人心,远近相安;这就是最好的生活</subtitle>
    <logo>http://lvelvis.github.io/images/avatar.png</logo>
    <icon>http://lvelvis.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, lvelvis</rights>
    <entry>
        <title type="html"><![CDATA[golang笔记-go-restful]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-go-restful/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-go-restful/">
        </link>
        <updated>2020-06-22T06:45:14.000Z</updated>
        <content type="html"><![CDATA[<p>用golang写一个restful api。如果您不知道什么是restful,可以看<a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html">阮一峰老师的教程</a></p>
<p>首先，我们需要解决的是路由的问题，也就是如何将不同的url映射到不同的处理函数。</p>
<pre><code>    router.GET(&quot;/api/todo/:todoid&quot;, getTodoById)
    router.POST(&quot;/api/todo/&quot;, addTodo)
    router.DELETE(&quot;/api/todo/:todoid&quot;, deleteTodo)
    router.PUT(&quot;/api/todo/:todoid&quot;, modifyTodo)
</code></pre>
<p>作为一个初学者，我马上打开github,找到了<a href="https://github.com/avelino/awesome-go">awesome-go</a>,经过一番调研，我感觉有几个http router的库比较适合：bone, httprouter, mux</p>
<h2 id="基本框架">基本框架</h2>
<p>首先，我们设计了四个路由，分别为根据Id获得todo，增加todo，修改todo，删除todo。这里关于解析路由参数，我们使用了httprouter.Params的ByName函数。</p>
<pre><code>package main

import (
  &quot;fmt&quot;
  &quot;github.com/julienschmidt/httprouter&quot;
  &quot;net/http&quot;
  &quot;log&quot;
  &quot;io&quot;
  &quot;io/ioutil&quot;
)

func getTodoById(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  fmt.Fprintf(w, &quot;getTodo %s\n&quot;, todoid)
}

func addTodo(w http.ResponseWriter, r *http.Request, _ httprouter.Params){
  body, _ := ioutil.ReadAll(io.LimitReader(r.Body, 1048576))
  fmt.Fprintf(w, &quot;addTodo! %s\n&quot;,body)
}

func deleteTodo(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  fmt.Fprintf(w, &quot;deleteTodo %s\n&quot;, todoid)
}

func modifyTodo(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  body, _ := ioutil.ReadAll(io.LimitReader(r.Body, 1048576))
  fmt.Fprintf(w, &quot;modifyTodo %s to %s\n&quot;, todoid, body)
}

func main() {
    router := httprouter.New()
    router.GET(&quot;/api/todo/:todoid&quot;, getTodoById)
    router.POST(&quot;/api/todo/&quot;, addTodo)
    router.DELETE(&quot;/api/todo/:todoid&quot;, deleteTodo)
    router.PUT(&quot;/api/todo/:todoid&quot;, modifyTodo)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, router))
}
</code></pre>
<p>我们可以用curl来测试一下我们的api,以put为例</p>
<pre><code>curl --data &quot;content=shopping&amp;time=tomorrow&quot; http://127.0.0.1:8080/api/todo/123 -X PUT

// modifyTodo 123 to content=shopping&amp;time=tomorrow
</code></pre>
<h2 id="json的解析">json的解析</h2>
<p>我们在使用restful api的时候，常常需要给后台传递数据。从上面可以看到，我们通过http.Request的Body属性可以获得数据</p>
<pre><code>body, _ := ioutil.ReadAll(io.LimitReader(r.Body, 1048576))
</code></pre>
<p>从上面，我们读出的数据是[]byte，但是我们希望将其解析为对象，那么在这之前，我们需要先定义我们的struct。假设我们的todo只有一个字段，就是Name</p>
<pre><code>type Todo struct {
    Name      string
}
</code></pre>
<p>现在我们可以这样解析</p>
<pre><code>var todo Todo;
json.Unmarshal(body, &amp;todo);
</code></pre>
<h2 id="model层设计">model层设计</h2>
<pre><code>package main

import (
  &quot;gopkg.in/mgo.v2&quot;
  &quot;fmt&quot;
  &quot;log&quot;
  &quot;gopkg.in/mgo.v2/bson&quot;
)

var session *mgo.Session

func init(){
  session,_ = mgo.Dial(&quot;mongodb://127.0.0.1&quot;)
}

type Todo struct {
    Name      string
}

func createTodo(t Todo){
  c := session.DB(&quot;test&quot;).C(&quot;todo&quot;)
  c.Insert(&amp;t)
}

func queryTodoById(id string){
  c := session.DB(&quot;test&quot;).C(&quot;todo&quot;)
  result := Todo{}

  err := c.Find(bson.M{&quot;_id&quot;: bson.ObjectIdHex(id)}).One(&amp;result)
  if err != nil {
    log.Fatal(err)
  }

  fmt.Println(&quot;Todo:&quot;, result.Name)
}

func removeTodo(id string){
  c := session.DB(&quot;test&quot;).C(&quot;todo&quot;)
  err := c.Remove(bson.M{&quot;_id&quot;: bson.ObjectIdHex(id)})
  if err != nil{
    log.Fatal(err)
  }
}

func updateTodo(id string, update interface{}){
  //change := bson.M{&quot;$set&quot;: bson.M{&quot;name&quot;: &quot;hahaha&quot;}}
  c := session.DB(&quot;test&quot;).C(&quot;todo&quot;)
  err := c.Update(bson.M{&quot;_id&quot;: bson.ObjectIdHex(id)}, update)
  if err != nil{
    log.Fatal(err)
  }
}
</code></pre>
<p>我们定义了Todo的struct,并添加了几种函数。</p>
<pre><code>package main

import (
  &quot;fmt&quot;
  &quot;github.com/julienschmidt/httprouter&quot;
  &quot;net/http&quot;
  &quot;log&quot;
  &quot;io&quot;
  &quot;io/ioutil&quot;
  &quot;encoding/json&quot;
  &quot;gopkg.in/mgo.v2/bson&quot;
)

func getTodoById(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  queryTodoById(todoid)
  fmt.Fprintf(w, &quot;getUser %s\n&quot;, todoid)
}

func addTodo(w http.ResponseWriter, r *http.Request, _ httprouter.Params){
  body, _ := ioutil.ReadAll(io.LimitReader(r.Body, 1048576))
  var todo Todo;
  json.Unmarshal(body, &amp;todo);
  createTodo(todo)
  fmt.Fprintf(w, &quot;addUser! %s\n&quot;,body)
}

func deleteTodo(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  removeTodo(todoid)
  fmt.Fprintf(w, &quot;deleteUser %s\n&quot;, todoid)
}

func modifyTodo(w http.ResponseWriter, r *http.Request, params httprouter.Params){
  todoid := params.ByName(&quot;todoid&quot;)
  body, _ := ioutil.ReadAll(io.LimitReader(r.Body, 1048576))
  var todo Todo
  json.Unmarshal(body, &amp;todo);
  change := bson.M{&quot;$set&quot;: bson.M{&quot;name&quot;: todo.Name}}
  updateTodo(todoid,change)
  fmt.Fprintf(w, &quot;modifyUser %s to %s\n&quot;, todoid, body)
}

func main() {
    router := httprouter.New()
    router.GET(&quot;/api/todo/:todoid&quot;, getTodoById)
    router.POST(&quot;/api/todo/&quot;, addTodo)
    router.DELETE(&quot;/api/todo/:todoid&quot;, deleteTodo)
    router.PUT(&quot;/api/todo/:todoid&quot;, modifyTodo)
    log.Fatal(http.ListenAndServe(&quot;:8080&quot;, router))
}</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[jenkins x on kubernetes实践(支持多主)]]></title>
        <id>http://lvelvis.github.io/post/jenkins-x-on-kubernetes-shi-jian-zhi-chi-duo-zhu/</id>
        <link href="http://lvelvis.github.io/post/jenkins-x-on-kubernetes-shi-jian-zhi-chi-duo-zhu/">
        </link>
        <updated>2020-06-18T02:26:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="jenkins是什么">jenkins是什么？</h2>
<p>Jenkins是一个开源的持续集成工具，可用于自动化的执行与构建，测试和交付或部署软件有关的各种任务,有非常丰富的插件支持。</p>
<h2 id="kubernetes是什么">kubernetes是什么？</h2>
<p>Kubernetes是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。这个视频生动地介绍了k8s</p>
<h2 id="jenkins-on-k8s-有什么好处">jenkins on k8s 有什么好处？</h2>
<p>jenkins通过单Master多个Slave的方式提供服务，Master保存了任务的配置信息，安装的插件等等，而slave主要负责执行任务，在使用中存在以下几个问题：</p>
<ol>
<li>当存在多个slave时，运行slave的机器难以统一管理，每次添加新节点时总要做大量的重复工作。</li>
<li>由于不同业务的构建频率并不相同，在使用会发现有很多slave大多数时间都处于空闲状态，造成资源浪费</li>
<li>jenkins默认采取保守的调度方式，造成某些slave的负载过高，任务不能平均分配</li>
</ol>
<h2 id="jenkins架构">jenkins架构</h2>
<p><img src="http://lvelvis.github.io/post-images/1592447693022.png" alt="" loading="lazy"><br>
使用k8s管理jenkins具有以下优势：</p>
<ol>
<li>使用docker运行jenkins保证环境的一致性，可以根据不同业务选择合适的镜像</li>
<li>k8s对抽象后的资源（pods）进行统一的管理调度，提供资源隔离和共享，使机器计算资源变得弹性可扩展,避免资源浪费。</li>
<li>k8s提供容器的自愈功能，能够保证始终有一定数量的容器是可用的</li>
<li>k8s默认的调度器提供了针对节点当前资源分配容器的调度策略，调度器支持插件化部署便于自定义。</li>
</ol>
<h2 id="一搭建环境">一，搭建环境</h2>
<h3 id="工具准备">工具准备</h3>
<pre><code>kubernetes v1.8.4
docker v1.12.6
jenkins master镜像 jenkins/jenkins:lts（v2.73.3）
slave镜像 jenkinsci/jnlp-slave
Kubernetes plugin (v1.1)
</code></pre>
<h3 id="安装kubernetes集群">安装kubernetes集群</h3>
<p>中文教程：https://www.kubernetes.org.cn/2906.html<br>
省略.....</p>
<h2 id="二创建statefulset">二，创建StatefulSet</h2>
<p>StatefulSet(有状态副本集)：Deployments适用于运行无状态应用，StatefulSet则为有状态的应用提供了支持，可以为应用提供有序的部署和扩展，稳定的持久化存储，我们使用SS来运行jenkins master。</p>
<p>创建完整的Stateful Set需要依次创建一下对象：<br>
1、Persistent Volume<br>
2、Persistent Volume Claim<br>
3、StatefulSet<br>
4、Service</p>
<p>创建PersistentVolume：<br>
为了保存应用运行时的数据需要先创建k8s的卷文件，K8s中存在Volume和PersistentVolume两种类型：</p>
<ol>
<li>Volume：与docker中的volume不同在于Volume生命周期是和pod绑定的，与pod中的container无关。k8s为Volume提供了多种类型文件系统（cephfs,nfs…,简单起见我直接选择了hostPath，使用的node节点本地的存储系统）</li>
<li>PersistentVolume:从名字可以看出来，PV的生命周期独立于使用它的pod，不会像volume随pod消失而消失，而是做为一个集群中的资源存在（像node节点一样），同时PV屏蔽了使用具体存储系统的细节。<br>
k8s中的对象都是通过yaml文件来定义的，首先创建名为jenkins-volume.yml的文件:</li>
</ol>
<p>❣️❣️注意：PV的创建有静态，动态两种方式，动态创建可以减少管理员的操作步骤，需要提供指定的StorageClass。为了测试方便，所以我们直接选择静态创建，manual是一个不存在的storage class</p>
<pre><code>kind: PersistentVolume
apiVersion: v1
metadata:
  name: jenkins-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/tmp/data&quot;
</code></pre>
<p>master节点执行下面的命令，PV就手动创建完了</p>
<pre><code>kubectl create -f jenkins-volume1.yaml
</code></pre>
<p>创建PersistentVolumeClaim：</p>
<pre><code>PersistentVolumeClaim(PVC):
持久化存储卷索取，如果说PV是集群中的资源，PVC就是资源的消费者，PVC可以指定需要的资源大小和访问方式,pod不会和PV直接接触，而是通过PVC来请求资源，PV的生成阶段叫做provision,生成PV后会绑定到PVC对象，然后才能被其他对象使用。
</code></pre>
<p>PV和PVC的生命周期如下图：<br>
<img src="http://lvelvis.github.io/post-images/1592447954632.png" alt="" loading="lazy">pv life<br>
创建文件jenkins-claim.yaml<br>
注意： name必须为jenkins-home-jenkins-0否则会绑定失败</p>
<pre><code>kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: jenkins-home-jenkins-0
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
</code></pre>
<p>执行命令kubectl create -f jenkins-claim.yaml<br>
然后查看PVC是否创建成功，status为bound说明PVC已经绑定</p>
<pre><code>[root@master ~]# kubectl describe pvc jenkins-home-jenkins-0
Name:          jenkins-home-jenkins-0
Namespace:     kubernetes-plugin
StorageClass:  manual
Status:        Bound
Volume:        jenkins-volume
Labels:        &lt;none&gt;
Annotations:   pv.kubernetes.io/bind-completed=yes
               pv.kubernetes.io/bound-by-controller=yes
Capacity:      10Gi
Access Modes:  RWO
Events:        &lt;none&gt;
</code></pre>
<p>创建StatefulSet和Service：<br>
从kubernetes-plugin github仓库下载jenkins.yml文件</p>
<pre><code>wget https://raw.githubusercontent.com/jenkinsci/kubernetes-plugin/master/src/main/kubernetes/jenkins.yml
修改jenkins.yml：
去掉87行externalTrafficPolicy: Local（这是GKE使用的）
修改83行type: LoadBalancer改为type: NodePort
</code></pre>
<p>注意：<br>
service type=ClusterIP时只允许从集群内部访问， type设置为NodePort是为了从集群外的机器访问jenkins,请谨慎使用，开启NodePort会在所有节点（含master）的统一固定端口开放服务。</p>
<p>执行命令</p>
<pre><code>[root@master ~]# kubectl create -f jenkins.yml 
statefulset &quot;jenkins&quot; created
service &quot;jenkins&quot; created
访问jenkins master,地址为masterip:32058
</code></pre>
<p>#查看映射的端口</p>
<pre><code>[root@master ~]# kubectl get service jenkins
NAME      TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)                        AGE
jenkins   NodePort   10.96.82.68   &lt;none&gt;        80:32058/TCP,50000:30345/TCP   1m

</code></pre>
<p>查看pod : jenkins-0的容器日志，粘贴下面的密码进入jenkins,jenkins安装完成。</p>
<pre><code>Jenkins initial setup is required. An admin user has been created and a password generated.
Please use the following password to proceed to installation:
70aa7b41ba894855abccd09306625b8a
</code></pre>
<h3 id="问题分析">问题分析</h3>
<p>1.创建stateful set时失败，提示”PersistentVolumeClaim is not bound: “jenkins-home-jenkins-0”：”<br>
因为采用静态创建PV时，StatefulSet会按照固定名称查找PVC，PVC的名字要满足</p>
<p>PVC_name == volumeClaimTemplates_name + “-“ + pod_name</p>
<p>这里的名字就是jenkins-home-jenkins-0</p>
<p>2.pod启动失败，jenkins用户没有目录权限<br>
错误提示”touch: cannot touch ‘/var/jenkins_home/copy_reference_file.log’: Permission denied<br>
Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions?”<br>
要确保节点目录开放权限,在node上执行命令：</p>
<pre><code>sudo chown -R 1000:1000 /var/jenkins_home/
sudo chown -R 1000:1000 /tmp/data
##如果仍然失败，尝试在node上重启docker
systemctl restart docker
</code></pre>
<p>注意pv指定的hostPath权限也要修改，否则是无效的</p>
<h2 id="三-配置jenkins">三 ，配置jenkins</h2>
<p>创建jenkins服务账号</p>
<pre><code>wget https://raw.githubusercontent.com/jenkinsci/kubernetes-plugin/master/src/main/kubernetes/service-account.yml
kubectl create -f service-account.yml
</code></pre>
<p>配置插件<br>
访问http://masterip:32058/pluginManager/,搜索插件Kubernetes plugin安装；<br>
访问 http://masterip:32058/configure<br>
选择新建云–kubernetes,在URl填写api server地址，<br>
执行kubectl describe命令，复制output中的token，填入到 ‘Kubernetes server certificate key’</p>
<p>[root@master ~]# kubectl get secret<br>
NAME                  TYPE                                  DATA      AGE<br>
default-token-4kb54   kubernetes.io/service-account-token   3         1d<br>
jenkins-token-wzbsx   kubernetes.io/service-account-token   3         1d<br>
[root@master ~]# kubectl describe secret/jenkins-token-wzbsx<br>
...<br>
jenkins url,tunnel填写service的CLUSTER-IP即可，结果如图：<br>
<img src="http://lvelvis.github.io/post-images/1592448124617.png" alt="" loading="lazy">peizhi1<br>
选择add pod template，填写下面的内容，retain slave可以设置运行jenkins slave 的container空闲后能存活多久。<br>
<img src="http://lvelvis.github.io/post-images/1592448148171.png" alt="" loading="lazy">content<br>
插件配置完成。</p>
<h2 id="四-测试">四 ，测试</h2>
<ol>
<li>扩容测试<br>
StatefulSet扩容：<br>
首先需要手动创建PV，PVC(见第二步),然后执行扩容命令</li>
</ol>
<pre><code>kubectl scale statefulset/jenkins --replicas=２
</code></pre>
<p>查看StatefulSet,此时已经拥有两个master节点，访问service时会随机将请求发送给后端的master。</p>
<pre><code>[root@master ~]# kubectl get statefulset/jenkins 
NAME      DESIRED   CURRENT   AGE
jenkins   2         2         5d
</code></pre>
<p>虽然通过k8s可以轻松实现jenkins master节点的拓展，但是由于jenkins存储数据的方式通过本地文件存储，master之间的数据同步还是一个麻烦的问题，参考jenkins存储模型。</p>
<p>jenkins master上保存的文件：</p>
<pre><code>ls /temp/data
jenkins.CLI.xml
jenkins.install.InstallUtil.lastExecVersion
jenkins.install.UpgradeWizard.state
jenkins.model.ArtifactManagerConfiguration.xml
jenkins.model.JenkinsLocationConfiguration.xml
jobs
logs
nodeMonitors.xml
nodes
</code></pre>
<ol start="2">
<li>高可用测试<br>
现在stateful set中已经有两个pod,在jenkins-1所在的节点执行docker stop停止运行jenkins-master的容器，同时在命令行查看pod的状态，可以看到jenkins-1异常（Error状态）之后慢慢恢复了运行状态（Running）：</li>
</ol>
<pre><code>[root@master ~]# kubectl get pods -w
NAME        READY     STATUS    RESTARTS   AGE
jenkins-0   1/1       Running   0          1d
jenkins-1   0/1       Running   1         20h
jenkins-1   1/1       Running   1         20h
jenkins-1   0/1       Error     1         20h
jenkins-1   0/1       CrashLoopBackOff   1         20h
jenkins-1   0/1       Running   2         20h
jenkins-1   1/1       Running   2         20h
</code></pre>
<p>kubectl describe pod jenkins-1查看pod的事件日志，k8s通过探针(probe)接口检测到服务停止之后自动执行了拉取镜像，重启container的操作。</p>
<pre><code>Events:
  Type     Reason      Age                From                              Message
  ----     ------      ----               ----                              -------
  Warning  Unhealthy   27m (x2 over 27m)  kubelet, iz8pscwd1fv6kprs1zw21kz  Readiness probe failed: HTTP probe failed with statuscode: 503
  Warning  Unhealthy   27m (x2 over 27m)  kubelet, iz8pscwd1fv6kprs1zw21kz  Liveness probe failed: HTTP probe failed with statuscode: 503
  Warning  Unhealthy   24m                kubelet, iz8pscwd1fv6kprs1zw21kz  Readiness probe failed: Get http://192.168.24.4:8080/login: dial tcp 192.168.24.4:8080: getsockopt: connection refused
  Warning  BackOff     20m (x2 over 20m)  kubelet, iz8pscwd1fv6kprs1zw21kz  Back-off restarting failed container
  Warning  FailedSync  20m (x2 over 20m)  kubelet, iz8pscwd1fv6kprs1zw21kz  Error syncing pod
  Normal   Pulling     19m (x3 over 20h)  kubelet, iz8pscwd1fv6kprs1zw21kz  pulling image &quot;jenkins/jenkins:lts-alpine&quot;
  Normal   Started     19m (x3 over 20h)  kubelet, iz8pscwd1fv6kprs1zw21kz  Started container
  Normal   Pulled      19m (x3 over 20h)  kubelet, iz8pscwd1fv6kprs1zw21kz  Successfully pulled image &quot;jenkins/jenkins:lts-alpine&quot;
  Normal   Created     19m (x3 over 20h)  kubelet, iz8pscwd1fv6kprs1zw21kz  Created container
</code></pre>
<ol start="3">
<li>jenkins构建测试<br>
当前集群中使用的jenkins slave镜像只包含一个java运行环境来运行jenkins-slave.jar,在实际使用中需要自定义合适的镜像。选择自定义镜像之后需要修改插件的配置，同样name命名为jnlp替换默认镜像，arguments安装工具提示填写即可。<br>
<img src="http://lvelvis.github.io/post-images/1592448208433.png" alt="" loading="lazy"><br>
创建job，同时开始构建,k8s会在不同节点上创建pod来运行任务</li>
</ol>
<p>jenkins默认调度策略</p>
<ol>
<li>尝试在上次构建的节点上构建，指定某台slave之后会一直使用。</li>
<li>当队列有2个构建时，不会立刻创建两个executor,而是先创建一个executor然后尝试等待executor空闲，目的是保证每个executor被充分利用。<br>
k8s调度策略<br>
使用Pod.spec.nodeSelector根据label为pod选择node<br>
3 .调度器scheduler有Predicates，Priorities两个阶段，分别负责节点过滤和评分排序，各个阶段都有k8s提供的检查项，我们可以自由组合。<br>
（比如PodFitsResources检查cpu内存等资源，PodFitsHostPorts检查端口占用，SelectorSpreadPriority要求一个服务尽量分散分布）自定义schduler参考<br>
资源不足时会发生什么<br>
当前集群中有3个节点，我在node2运行一个CPU占用限制在80%的程序,然后设置jenkins插件ContainerTemplate的request和limit均为cpu 500m,内存500Mi,（500m代表单核CPU的50%）看一下pod会怎么调度<br>
k8s仍然尝试在node2分配节点（为什么其他节点不行），结果POD处于pending状态：</li>
</ol>
<pre><code>{
&quot;phase&quot;: &quot;Pending&quot;,
&quot;conditions&quot;: [
  {
    &quot;type&quot;: &quot;PodScheduled&quot;,
    &quot;status&quot;: &quot;False&quot;,
    &quot;lastProbeTime&quot;: null,
    &quot;lastTransitionTime&quot;: &quot;2017-12-09T08:29:10Z&quot;,
    &quot;reason&quot;: &quot;Unschedulable&quot;,
    &quot;message&quot;: &quot;No nodes are available that match all of the predicates: Insufficient cpu (4), PodToleratesNodeTaints (1).&quot;
  }
],
&quot;qosClass&quot;: &quot;Guaranteed&quot;
</code></pre>
<p>最后pod被删除，而jenkins任务会阻塞一直到有其他空闲的slave出现。</p>
<h2 id="五总结">五，总结</h2>
<p>本文介绍了在k8s集群部署jenkins服务的方式和k8s带来的资源管理便捷，由于我也是刚开始接触k8s,所用的实例只是搭建了用于测试的实验环境，离在实际生产环境中使用还有问题需要验证。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[consul-删除无效服务与节点]]></title>
        <id>http://lvelvis.github.io/post/consul-shan-chu-wu-xiao-fu-wu-yu-jie-dian/</id>
        <link href="http://lvelvis.github.io/post/consul-shan-chu-wu-xiao-fu-wu-yu-jie-dian/">
        </link>
        <updated>2020-06-17T09:43:15.000Z</updated>
        <content type="html"><![CDATA[<p>consul删除无效实例<br>
http://127.0.0.1:8500/v1/agent/service/deregister/test-9c14fa595ddfb8f4c34c673c65b072bb</p>
<p>test-9c14fa595ddfb8f4c34c673c65b072bb : 实例id<br>
method : put</p>
<p>删除无效节点<br>
http://127.0.0.1:8500/v1/v1/agent/force-leave/4b36b27317a0</p>
<p>consul leave #关闭consul并离开集群。也可以使用Ctrl+C或kill -INT来gracefully停止agent，这种体面的离开方式让consule可以有机会通知集群其他成员自己的离开。如果你强制地结束了agent，其他member会检测到这个节点的failed。当成员离开时，它的services和checks都会从catalog中移除。当成员failed时，它的health只是简单的被标记为critical，并不会从catalog中移除。Consul会自动尝试重新连接failed节点，允许它从恶劣的网络环境中恢复，显然离开的nodes不会被重新连接。另外，如果这个节点是server，体面的离开对避免潜在的中断的可能很重要。<br>
为了防止dead nodes的积累，consul会自动把dead nodes移除出catalog。这个过程被称为reaping（收割）。默认是72小时的间隔（不建议更改）</p>
<pre><code>#!/bin/bash
clear 
echo &quot;node_exporter注销工具&quot;
read -p &quot;请输入要踢掉的节点IP,如果有多个IP,请使用英文格式 ',' 隔开: &quot; IP_LIST

for IP in `echo &quot;${IP_LIST}&quot;|awk -F, 'BEGIN{OFS=&quot; &quot;}{$1=$1;printf(&quot;%s&quot;,$0);}'`
do 
   curl -XPUT http://10.100.x.x:8500/v1/agent/service/deregister/node-${IP}
   echo &quot;${IP}节点已剔除!&quot;
done
echo &quot;${IP_LIST}完成剔除&quot;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[docker - 内存使用率差异:cgroup memory.usage_in_bytes与docker容器内的RSS]]></title>
        <id>http://lvelvis.github.io/post/docker-nei-cun-shi-yong-lu-chai-yi-cgroup-memoryusage_in_bytes-yu-docker-rong-qi-nei-de-rss/</id>
        <link href="http://lvelvis.github.io/post/docker-nei-cun-shi-yong-lu-chai-yi-cgroup-memoryusage_in_bytes-yu-docker-rong-qi-nei-de-rss/">
        </link>
        <updated>2020-06-17T03:46:43.000Z</updated>
        <content type="html"><![CDATA[<p>&quot;kubernetes&quot;（v1.10.2）表示我的pod（包含一个容器）使用了大约5GB的内存。在容器内部，RSS说的更像681Mib。任何人都能用以下数据解释如何从681Mib到5GB吗（或者用我省略的另一个命令来描述如何弥补差异，无论是从容器还是从在Kubernetes中运行此容器的Docker主机）？<br>
Kubectl Top Pods表示5GB：</p>
<pre><code>% kubectl top pods -l app=myapp
NAME                             CPU(cores)   MEMORY(bytes)
myapp-56b947bf6d-2lcr7           39m          5039Mi
</code></pre>
<p>Cadvisor报告了类似的数字（可能来自稍有不同的时间，因此请忽略细微的差异）：</p>
<pre><code>container_memory_usage_bytes{pod_name=~&quot;.*myapp.*&quot;}      5309456384

5309456384 / 1024.0 / 1024 ~= 5063 ~= 5039
</code></pre>
<p>在容器中，此文件似乎是cadvisor获取其数据的位置：</p>
<pre><code># kubectl exec -it myapp-56b947bf6d-2lcr7 bash
meme@myapp-56b947bf6d-2lcr7:/app# cat /sys/fs/cgroup/memory/memory.usage_in_bytes
5309456384
容器中的常驻集大小（RSS）不匹配（小于1GB）：
meme@myapp-56b947bf6d-2lcr7:/app# kb=$(ps aux | grep -v grep | grep -v 'ps aux' | grep -v bash | grep -v awk | grep -v RSS | awk '{print $6}' | awk '{s+=$1} END {printf &quot;%.0f&quot;, s}'); mb=$(expr $kb / 1024); printf &quot;Kb: $kb\nMb: $mb\n&quot;
Kb: 698076
Mb: 681
</code></pre>
<pre><code>完整的PS AUX，以防有帮助：
meme@myapp-56b947bf6d-2lcr7:/app# ps aux | grep -v grep | grep -v 'ps aux' | grep -v bash | grep -v awk
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
meme         1  0.0  0.0 151840 10984 ?        Ss   Jun04   0:29 /usr/sbin/apache2 -D FOREGROUND
www-data    10  0.0  0.0 147340  4652 ?        S    Jun04   0:00 /usr/sbin/apache2 -D FOREGROUND
www-data    11  0.0  0.0 148556  4392 ?        S    Jun04   0:16 /usr/sbin/apache2 -D FOREGROUND
www-data    12  0.2  0.0 2080632 11348 ?       Sl   Jun04  31:58 /usr/sbin/apache2 -D FOREGROUND
www-data    13  0.1  0.0 2080384 10980 ?       Sl   Jun04  18:12 /usr/sbin/apache2 -D FOREGROUND
www-data    68  0.3  0.0 349048 94272 ?        Sl   Jun04  47:09 hotapp
www-data   176  0.2  0.0 349624 92888 ?        Sl   Jun04  43:11 hotapp
www-data   179  0.2  0.0 349196 94456 ?        Sl   Jun04  42:20 hotapp
www-data   180  0.3  0.0 349828 95112 ?        Sl   Jun04  44:14 hotapp
www-data   185  0.3  0.0 346644 91948 ?        Sl   Jun04  43:49 hotapp
www-data   186  0.3  0.0 346208 91568 ?        Sl   Jun04  44:27 hotapp
www-data   189  0.2  0.0 350208 95476 ?        Sl   Jun04  41:47 hotapp
</code></pre>
<p>Docker容器统计API中的内存部分：</p>
<pre><code>curl --unix-socket /var/run/docker.sock 'http:/v1.24/containers/a45fc651e7b12f527b677e6a46e2902786bee6620484922016a135e317a42b4e/stats?stream=false' | jq . # yields:

&quot;memory_stats&quot;: {
  &quot;usage&quot;: 5327712256,
  &quot;max_usage&quot;: 5368344576,
  &quot;stats&quot;: {
    &quot;active_anon&quot;: 609095680,
    &quot;active_file&quot;: 74457088,
    &quot;cache&quot;: 109944832,
    &quot;dirty&quot;: 28672,
    &quot;hierarchical_memory_limit&quot;: 5368709120,
    &quot;inactive_anon&quot;: 1687552,
    &quot;inactive_file&quot;: 29974528,
    &quot;mapped_file&quot;: 1675264,
    &quot;pgfault&quot;: 295316278,
    &quot;pgmajfault&quot;: 77,
    &quot;pgpgin&quot;: 85138921,
    &quot;pgpgout&quot;: 84964308,
    &quot;rss&quot;: 605270016,
    &quot;rss_huge&quot;: 0,
    &quot;shmem&quot;: 5513216,
    &quot;total_active_anon&quot;: 609095680,
    &quot;total_active_file&quot;: 74457088,
    &quot;total_cache&quot;: 109944832,
    &quot;total_dirty&quot;: 28672,
    &quot;total_inactive_anon&quot;: 1687552,
    &quot;total_inactive_file&quot;: 29974528,
    &quot;total_mapped_file&quot;: 1675264,
    &quot;total_pgfault&quot;: 295316278,
    &quot;total_pgmajfault&quot;: 77,
    &quot;total_pgpgin&quot;: 85138921,
    &quot;total_pgpgout&quot;: 84964308,
    &quot;total_rss&quot;: 605270016,
    &quot;total_rss_huge&quot;: 0,
    &quot;total_shmem&quot;: 5513216,
    &quot;total_unevictable&quot;: 0,
    &quot;total_writeback&quot;: 0,
    &quot;unevictable&quot;: 0,
    &quot;writeback&quot;: 0
  },
  &quot;limit&quot;: 5368709120
},
</code></pre>
<p>对断言的注释：<br>
总计（memory.usage_in_bytes）=rss+缓存<br>
说：<br>
用法\u字节：为了提高效率，与其他内核组件一样，内存组使用一些优化<br>
避免不必要的缓存线错误共享。使用率受<br>
方法，不显示内存（和交换）使用的“精确”值，这是一个模糊的<br>
有效访问的值。（当然，必要时，它是同步的。）<br>
如果您想知道更精确的内存使用情况，应该使用rss+cache（+swap）<br>
内存中的值。stat（见5.2）。<br>
说：<br>
注意：在Linux上，Docker CLI通过从总内存使用量中减去页面缓存使用量来报告内存使用情况。API不执行这样的计算，而是提供总内存使用量和页面缓存的数量，以便客户机可以根据需要使用数据。<br>
实际上，容器中/sys/fs/cgroup/memory/memory.stat中的大多数内容都出现在上面的docker stats api响应中（与在不同时间采集样本略有不同，抱歉）：</p>
<pre><code>meme@myapp-56b947bf6d-2lcr7:/app# cat /sys/fs/cgroup/memory/memory.stat
cache 119492608
rss 607436800
rss_huge 0
shmem 5525504
mapped_file 1675264
dirty 69632
writeback 0
pgpgin 85573974
pgpgout 85396501
pgfault 296366011
pgmajfault 80
inactive_anon 1687552
active_anon 611213312
inactive_file 32800768
active_file 81166336
unevictable 0
hierarchical_memory_limit 5368709120
total_cache 119492608
total_rss 607436800
total_rss_huge 0
total_shmem 5525504
total_mapped_file 1675264
total_dirty 69632
total_writeback 0
total_pgpgin 85573974
total_pgpgout 85396501
total_pgfault 296366011
total_pgmajfault 80
total_inactive_anon 1687552
total_active_anon 611213312
total_inactive_file 32800768
total_active_file 81166336
total_unevictable 0
</code></pre>
<p>内存信息来自：<br>
Limits:<br>
memory:  5Gi<br>
Requests:<br>
memory:   4Gi</p>
<p>下面是容器内的提示。在这一行程序中，我获取所有进程ID，在它们上运行pmap-x，并从pmap结果中提取kbytes列。总的结果是256兆字节（远小于PS的RSS，我认为部分原因是许多进程没有从PMAP-X返回输出）：</p>
<pre><code>ps aux | awk '{print $2}' | grep -v PID | xargs sudo pmap -x | grep total | grep -v grep | awk '{print $3}' | awk '{s+=$1} END {printf &quot;%.0f&quot;, s}'; echo
256820
</code></pre>
<p>https://github.com/google/cadvisor/issues/638中提到了。它检查kubectl describe pod <pod>和pmap。这里没有照明（同样，它似乎忽略了一些过程）：</p>
<pre><code># python ps_mem.py
Private  +   Shared  =  RAM used    Program

  1.7 MiB +   1.0 MiB =   2.7 MiB   apache2
  2.0 MiB +   1.0 MiB =   3.0 MiB   bash (3)
---------------------------------
                          5.7 MiB
=================================
</code></pre>
<p>最佳答案</p>
<pre><code>有一件事我没看到您检查这里是内核内存。这在memory.usage_in_bytes图中也有说明，但在memory.stat中没有出现。您可以通过查看/sys/fs/cgroup/memory/memory.kmem.usage_in_bytes找到它。
有一次，我看到我们的一个.NET核心应用程序也发生了类似的事情，但我不知道到底发生了什么（可能是.NET核心内存泄漏，因为它是我们的应用程序无法控制的非托管内存）。这将取决于您的应用程序使用是否正常，但就cgroups而言，我相信内核内存使用在默认情况下是不受约束的。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang笔记-go mod与go vendor]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-go-mod-yu-go-vendor/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-go-mod-yu-go-vendor/">
        </link>
        <updated>2020-06-10T08:40:20.000Z</updated>
        <content type="html"><![CDATA[<h1 id="go-mod-使用">go mod 使用</h1>
<p>解决的问题是golang不再依赖gopath的设置，下载下来的包可以直接使用。<br>
go mod init ./<br>
go build main.go 或 go build -mod=vendor main.go<br>
go mod vendor #将包打到vendor文件夹下</p>
<h1 id="go-vendor">go vendor</h1>
<p>管理Golang项目依赖，应该是一个第三方的，但是比较好用。</p>
<p>安装<br>
go get -u github.com/kardianos/govendor</p>
<p>使用一套连招：</p>
<pre><code>govendor init # 创建vendor目录，创建vendor.json文件  
govendor add +external #生成依赖包  
govendor update +vendor # 更新vendor的包命令  
状态	缩写状态	含义
+local	l	本地包，即项目自身的包组织
+external	e	外部包，即被 $GOPATH 管理，但不在 vendor 目录下
+vendor	v	已被 govendor 管理，即在 vendor 目录下
+std	s	标准库中的包
+unused	u	未使用的包，即包在 vendor 目录下，但项目并没有用到
+missing	m	代码引用了依赖包，但该包并没有找到
+program	p	主程序包，意味着可以编译为执行文件
+outside	 	外部包和缺失的包
+all	 	所有的包
命令	功能
init	初始化 vendor 目录
list	列出所有的依赖包
add	添加包到 vendor 目录，如 govendor add +external 添加所有外部包
add PKG_PATH	添加指定的依赖包到 vendor 目录
update	从 $GOPATH 更新依赖包到 vendor 目录
remove	从 vendor 管理中删除依赖
status	列出所有缺失、过期和修改过的包
fetch	添加或更新包到本地 vendor 目录
sync	本地存在 vendor.json 时候拉去依赖包，匹配所记录的版本
get	类似 go get 目录，拉取依赖包到 vendor 目录
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang笔记-zip日志使用]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-zip-ri-zhi-shi-yong/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-zip-ri-zhi-shi-yong/">
        </link>
        <updated>2020-06-03T06:17:23.000Z</updated>
        <content type="html"><![CDATA[<p>在beego中使用zap管理日志，很方便👍<br>
需要在conf/app.conf定义几个参数</p>
<pre><code>appname = web-terminal
httpport = &quot;9600&quot;

runmode = &quot;prod&quot;
LogLevel = &quot;info&quot;
autorender = true
recoverpanic = false
copyrequestbody = true
viewspath = &quot;static&quot;
LogPath = &quot;logs/k8s-websocket.log&quot;
</code></pre>
<p>logger.go</p>
<pre><code>package controllers

import (
	&quot;os&quot;

	&quot;github.com/astaxie/beego&quot;
	&quot;github.com/natefinch/lumberjack&quot;
	&quot;go.uber.org/zap&quot;
	&quot;go.uber.org/zap/zapcore&quot;
)

//MyLogger初始化zaplogger日志库
var MyLogger *zap.Logger

func initLogger(logpath string, loglevel string) *zap.Logger {

	// 设置日志级别
	var level zapcore.Level
	switch loglevel {
	case &quot;debug&quot;:
		level = zap.DebugLevel
	case &quot;info&quot;:
		level = zap.InfoLevel
	case &quot;error&quot;:
		level = zap.ErrorLevel
	default:
		level = zap.InfoLevel
	}

	hook := lumberjack.Logger{
		Filename:   logpath, // 日志文件路径
		MaxSize:    20,      // 每个日志文件保存的最大尺寸 单位：M
		MaxBackups: 10,      // 日志文件最多保存多少个备份
		MaxAge:     7,       // 文件最多保存多少天
		Compress:   true,    // 是否压缩
	}

	encoderConfig := zapcore.EncoderConfig{
		TimeKey:        &quot;time&quot;,
		LevelKey:       &quot;level&quot;,
		NameKey:        &quot;logger&quot;,
		CallerKey:      &quot;linenum&quot;,
		MessageKey:     &quot;msg&quot;,
		StacktraceKey:  &quot;stacktrace&quot;,
		LineEnding:     zapcore.DefaultLineEnding,
		EncodeLevel:    zapcore.LowercaseLevelEncoder,  // 小写编码器
		EncodeTime:     zapcore.ISO8601TimeEncoder,     // ISO8601 UTC 时间格式
		EncodeDuration: zapcore.SecondsDurationEncoder, //
		EncodeCaller:   zapcore.ShortCallerEncoder,     // 短路径编码器
		EncodeName:     zapcore.FullNameEncoder,
	}

	core := zapcore.NewCore(
		zapcore.NewJSONEncoder(encoderConfig),                                           // 编码器配置
		zapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout), zapcore.AddSync(&amp;hook)), // 打印到控制台和文件
		level, // 日志级别
	)

	// 开启开发模式，堆栈跟踪
	caller := zap.AddCaller()
	// 开启文件及行号
	development := zap.Development()

	// 设置初始化字段
	filed := zap.Fields(zap.String(&quot;serviceName&quot;, &quot;k8s-websocket-dashboard&quot;))
	// 构造日志
	logger := zap.New(core, caller, development, filed)

	logger.Info(&quot;initlog 初始化成功&quot;)
	return logger
}

// 初始化日志
func init() {
	logPath := beego.AppConfig.String(&quot;LogPath&quot;)
	loglevel := beego.AppConfig.String(&quot;LogLevel&quot;)
	MyLogger = initLogger(logPath, loglevel)
}
</code></pre>
<p>日志输出：</p>
<pre><code>{&quot;level&quot;:&quot;info&quot;,&quot;time&quot;:&quot;2020-06-02T19:41:37.799+0800&quot;,&quot;linenum&quot;:&quot;controllers/logger.go:59&quot;,&quot;msg&quot;:&quot;log 初始化成功&quot;,&quot;serviceName&quot;:&quot;k8s-websocket-dashboard&quot;}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang笔记-beego获取url请求的参数]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-beego-huo-qu-url-qing-qiu-de-can-shu/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-beego-huo-qu-url-qing-qiu-de-can-shu/">
        </link>
        <updated>2020-06-02T04:00:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="获取参数">获取参数</h1>
<p>我们经常需要获取用户传递的数据，包括Get、POST等方式的请求，beego里面会自动解析这些数据，你可以通过如下方式获取数据：</p>
<p>GetString(key string) string<br>
GetStrings(key string) []string<br>
GetInt(key string) (int64, error)<br>
GetBool(key string) (bool, error)<br>
GetFloat(key string) (float64, error)<br>
示例1：</p>
<pre><code>func (this *MainController) Post() {
    jsoninfo := &lt;strong&gt;this.GetString&lt;/strong&gt;(&quot;jsoninfo&quot;)
    if jsoninfo == &quot;&quot; {
        this.Ctx.WriteString(&quot;jsoninfo is empty&quot;)
        return
    }
}```
如果你需要的数据可能是其它类型，例如是int类型而不是int64，那么你需要这样处理：

示例2：
</code></pre>
<p>func (this *MainController) Post() {<br>
id := <strong>this.Input().Get</strong>(&quot;id&quot;)<br>
intid, err := <strong>strconv.Atoi</strong>(id)<br>
}```<br>
更多其他的request的信息，用户可以通过this.Ctx.Request获取信息。</p>
<p>关于该对象的属性和方法可参考request官方手册https://gowalker.org/net/http#Request</p>
<h1 id="直接解析到struct">直接解析到struct</h1>
<p>如果要把表单里的内容赋值到一个struct里，除了用上面的方法一个一个获取再赋值之外，<br>
beego提供了通过另外一个更便捷的方式，就是通过struct的字段名或tag与表单字段对应直接解析到struct。</p>
<p>示例3：</p>
<p>定义struct</p>
<pre><code>type user struct {
    Id    int         `form:&quot;-&quot;`
    Name  interface{} `form:&quot;&lt;strong&gt;username&lt;/strong&gt;&quot;`
    Age   int         `form:&quot;&lt;strong&gt;age&lt;/strong&gt;&quot;`
    Email string
}
</code></pre>
<p>表单</p>
<pre><code>&lt;form id=&quot;&lt;strong&gt;user&lt;/strong&gt;&quot;&gt;
    名字：&lt;input name=&quot;&lt;strong&gt;username&lt;/strong&gt;&quot; type=&quot;text&quot; /&gt;
    年龄：&lt;input name=&quot;&lt;strong&gt;age&lt;/strong&gt;&quot; type=&quot;text&quot; /&gt;
    邮箱：&lt;input name=&quot;Email&quot; type=&quot;text&quot; /&gt;
    &lt;input type=&quot;submit&quot; value=&quot;提交&quot; /&gt;
&lt;/form&gt;
</code></pre>
<p>controller里解析</p>
<pre><code>func (this *MainController) Post() {
    u := &lt;strong&gt;user{}&lt;/strong&gt;
    if err := this.ParseForm(&lt;strong&gt;&amp;u&lt;/strong&gt;); err != nil {
        //handle error
    }
}　　
</code></pre>
<p>需要说明的是：</p>
<p>（1）structTag form的定义和renderform方法共用一个标签。</p>
<p>（2）定义struct时，字段名后如果有form这个tag，则会把form表单里的name和tag的名字一样的字段赋值给这个字段，</p>
<p>否则就会把form表单里与字段名一样的表单内容赋值给这个字段。</p>
<p>例如上面的例子中，会把表单中的username和age分别赋值给user里的Name和Age字段，而Email里的内容则会赋值给Email这个字段。</p>
<p>（3）调用Controller PraseForm这个方法的时候，传入的参数必须为一个struct的指针，否则对struct的赋值不会成功并返回xx must be a struct pointer的错误。</p>
<p>（4）如果要忽略一个字段，有两种方法，一是：字段名小写开头，二是：form标签设置为_</p>
<h1 id="获取request-body里的内容">获取Request Body里的内容</h1>
<p>在API的开发中，我们经常会用到JSON或XML来作为数据交互的格式，如何在beego中获取Request Body里的JSON或XML的数据呢？</p>
<p>首先，在配置文件里设置copyrequestbody = true</p>
<p>其次，在Controller中：</p>
<p>示例4：</p>
<pre><code>func (this *ObjectController) Post() {
    var ob models.Object
    var err error
    if err = json.Unmarshal(this.Ctx.Input.RequestBody, &amp;ob); err == nil {
        objectid := models.AddOne(ob)
        this.Data[&quot;json&quot;] = &quot;{\&quot;ObjectId\&quot;:\&quot;&quot; + objectid + &quot;\&quot;}&quot;
    } else {
        this.Data[&quot;json&quot;] = err.Error()
    }
    this.ServeJSON()
}
</code></pre>
<p></p>
<h1 id="文件上传">文件上传</h1>
<p>在beego中你可以很容易的处理文件上传，就是别忘记在你的form表单中增加“enctype=&quot;multipart/form-data”，否则你的浏览器不会传输你的上传文件。</p>
<p>文件上传之后一般是放在系统的内存里面，如果文件的size大于设置的缓存大小，那么就放在临时文件中，</p>
<p>默认的缓存内存是64M，你可以通过如下方式来调整这个缓存内存的大小。</p>
<p>beego.MaxMemory = 1&lt;&lt;22<br>
或者在配置文件中通过如下设置：</p>
<p>maxmemory = 1&lt;&lt;22<br>
Beego提供了两个很方便的方法来处理文件上传：</p>
<p>（1）GetFile(key string) (multipart.File, *multipart.FileHeader, error)</p>
<p>该方法主要用于用户读取表单中的文件名the_file，然后返回相应的信息，用户根据这些变量来处理文件上传：过滤、保存文件等。</p>
<p>（2）SaveToFile(fromfile, tofile string) error</p>
<p>该方法是在GetFile的基础上实现了快速保存的功能，fromfile是提交的时候html表单中的name。</p>
<p>示例5</p>
<p>表单：</p>
<pre><code>&lt;form enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt;
    &lt;input type=&quot;file&quot; name=&quot;uploadname&quot; /&gt;
    &lt;input type=&quot;submit&quot;&gt;
&lt;/form&gt;
</code></pre>
<p>Controller中代码：</p>
<pre><code>func (c *FormController) Post() {
    f, h, err := c.GetFile(&quot;uploadname&quot;)
    if err != nil {
        log.Fatal(&quot;getfile err &quot;, err)
    }
    defer f.Close()
    c.SaveToFile(&quot;uploadname&quot;, &quot;static/upload/&quot; + h.Filename) // 保存位置在 static/upload, 没有文件夹要先创建
     
}
</code></pre>
<h1 id="数据绑定">数据绑定</h1>
<p>支持从用户请求中直接数据bind到指定的对象。</p>
<p>示例6：</p>
<pre><code>var id int
this.Ctx.Input.Bind(&amp;id, &quot;id&quot;)  //id ==123
 
var isok bool
this.Ctx.Input.Bind(&amp;isok, &quot;isok&quot;)  //isok ==true
 
var ft float64
this.Ctx.Input.Bind(&amp;ft, &quot;ft&quot;)  //ft ==1.2
 
ol := make([]int, 0, 2)
this.Ctx.Input.Bind(&amp;ol, &quot;ol&quot;)  //ol ==[1 2]
 
ul := make([]string, 0, 2)
this.Ctx.Input.Bind(&amp;ul, &quot;ul&quot;)  //ul ==[str array]
 
user struct{Name}
this.Ctx.Input.Bind(&amp;user, &quot;user&quot;)  //user =={Name:&quot;astaxie&quot;}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang笔记-json数据解析：Marshal与Unmarshal]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-json-shu-ju-jie-xi-marshal-yu-unmarshal/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-json-shu-ju-jie-xi-marshal-yu-unmarshal/">
        </link>
        <updated>2020-05-28T10:15:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="简介">简介</h1>
<p>Json(Javascript Object Nanotation)是一种数据交换格式，常用于前后端数据传输。任意一端将数据转换成json 字符串，另一端再将该字符串解析成相应的数据结构，如string类型，strcut对象等。</p>
<p>go语言本身为我们提供了json的工具包”encoding/json”。<br>
更多的使用方式，可以参考：https://studygolang.com/articles/6742</p>
<h1 id="实现">实现</h1>
<p>Json Marshal：将数据编码成json字符串<br>
看一个简单的例子</p>
<pre><code>type Stu struct {
    Name  string `json:&quot;name&quot;`
    Age   int
    HIgh  bool
    sex   string
    Class *Class `json:&quot;class&quot;`
}

type Class struct {
    Name  string
    Grade int
}

func main() {
    //实例化一个数据结构，用于生成json字符串
    stu := Stu{
        Name: &quot;张三&quot;,
        Age:  18,
        HIgh: true,
        sex:  &quot;男&quot;,
    }

    //指针变量
    cla := new(Class)
    cla.Name = &quot;1班&quot;
    cla.Grade = 3
    stu.Class=cla

    //Marshal失败时err!=nil
    jsonStu, err := json.Marshal(stu)
    if err != nil {
        fmt.Println(&quot;生成json字符串错误&quot;)
    }

    //jsonStu是[]byte类型，转化成string类型便于查看
    fmt.Println(string(jsonStu))
}
</code></pre>
<p>结果：</p>
<pre><code>{&quot;name&quot;:&quot;张三&quot;,&quot;Age&quot;:18,&quot;HIgh&quot;:true,&quot;class&quot;:{&quot;Name&quot;:&quot;1班&quot;,&quot;Grade&quot;:3}}
</code></pre>
<p>从结果中可以看出</p>
<p>只要是可导出成员（变量首字母大写），都可以转成json。因成员变量sex是不可导出的，故无法转成json。</p>
<p>如果变量打上了json标签，如Name旁边的 <code>json:&quot;name&quot;</code> ，那么转化成的json key就用该标签“name”，否则取变量名作为key，如“Age”，“HIgh”。</p>
<p>bool类型也是可以直接转换为json的value值。Channel， complex 以及函数不能被编码json字符串。当然，循环的数据结构也不行，它会导致marshal陷入死循环。</p>
<p>指针变量，编码时自动转换为它所指向的值，如cla变量。<br>
（当然，不传指针，Stu struct的成员Class如果换成Class struct类型，效果也是一模一样的。只不过指针更快，且能节省内存空间。）</p>
<p>最后，强调一句：json编码成字符串后就是纯粹的字符串了。</p>
<p>上面的成员变量都是已知的类型，只能接收指定的类型，比如string类型的Name只能赋值string类型的数据。<br>
但有时为了通用性，或使代码简洁，我们希望有一种类型可以接受各种类型的数据，并进行json编码。这就用到了interface{}类型。</p>
<p>前言：<br>
interface{}类型其实是个空接口，即没有方法的接口。go的每一种类型都实现了该接口。因此，任何其他类型的数据都可以赋值给interface{}类型。</p>
<pre><code>type Stu struct {
    Name  interface{} `json:&quot;name&quot;`
    Age   interface{}
    HIgh  interface{}
    sex   interface{}
    Class interface{} `json:&quot;class&quot;`
}

type Class struct {
    Name  string
    Grade int
}

func main() {
    //与前面的例子一样
    ......
}
</code></pre>
<p>结果：</p>
<pre><code>{&quot;name&quot;:&quot;张三&quot;,&quot;Age&quot;:18,&quot;HIgh&quot;:true,&quot;class&quot;:{&quot;Name&quot;:&quot;1班&quot;,&quot;Grade&quot;:3}}
</code></pre>
<p>从结果中可以看出，无论是string，int，bool，还是指针类型等，都可赋值给interface{}类型，且正常编码，效果与前面的例子一样。</p>
<p>补充：<br>
在实际项目中，编码成json串的数据结构，往往是切片类型。如下定义了一个[]StuRead类型的切片</p>
<pre><code>//正确示范

//方式1：只声明，不分配内存
var stus1 []*StuRead

//方式2：分配初始值为0的内存
stus2 := make([]*StuRead,0)

//错误示范
//new()只能实例化一个struct对象，而[]StuRead是切片，不是对象
stus := new([]StuRead)

stu1 := StuRead{成员赋值...}
stu2 := StuRead{成员赋值...}

//由方式1和2创建的切片，都能成功追加数据
//方式2最好分配0长度，append时会自动增长。反之指定初始长度，长度不够时不会自动增长，导致数据丢失
stus1 := appen(stus1,stu1,stu2)
stus2 := appen(stus2,stu1,stu2)

//成功编码
json1,_ := json.Marshal(stus1)
json2,_ := json.Marshal(stus2)
</code></pre>
<p>解码时定义对应的切片接受即可</p>
<p>Json Unmarshal：将json字符串解码到相应的数据结构<br>
我们将上面的例子进行解码</p>
<pre><code>type StuRead struct {
    Name  interface{} `json:&quot;name&quot;`
    Age   interface{}
    HIgh  interface{}
    sex   interface{}
    Class interface{} `json:&quot;class&quot;`
    Test  interface{}
}

type Class struct {
    Name  string
    Grade int
}

func main() {
    //json字符中的&quot;引号，需用\进行转义，否则编译出错
    //json字符串沿用上面的结果，但对key进行了大小的修改，并添加了sex数据
    data:=&quot;{\&quot;name\&quot;:\&quot;张三\&quot;,\&quot;Age\&quot;:18,\&quot;high\&quot;:true,\&quot;sex\&quot;:\&quot;男\&quot;,\&quot;CLASS\&quot;:{\&quot;naME\&quot;:\&quot;1班\&quot;,\&quot;GradE\&quot;:3}}&quot;
    str:=[]byte(data)

    //1.Unmarshal的第一个参数是json字符串，第二个参数是接受json解析的数据结构。
    //第二个参数必须是指针，否则无法接收解析的数据，如stu仍为空对象StuRead{}
    //2.可以直接stu:=new(StuRead),此时的stu自身就是指针
    stu:=StuRead{}
    err:=json.Unmarshal(str,&amp;stu)

    //解析失败会报错，如json字符串格式不对，缺&quot;号，缺}等。
    if err!=nil{
        fmt.Println(err)
    }

    fmt.Println(stu)
}
</code></pre>
<p>结果：</p>
<pre><code>{张三 18 true &lt;nil&gt; map[naME:1班 GradE:3] &lt;nil&gt;}
</code></pre>
<p>总结：</p>
<p>json字符串解析时，需要一个“接收体”接受解析后的数据，且Unmarshal时接收体必须传递指针。否则解析虽不报错，但数据无法赋值到接受体中。如这里用的是StuRead{}接收。</p>
<p>解析时，接收体可自行定义。json串中的key自动在接收体中寻找匹配的项进行赋值。匹配规则是：</p>
<p>先查找与key一样的json标签，找到则赋值给该标签对应的变量(如Name)。<br>
没有json标签的，就从上往下依次查找变量名与key一样的变量，如Age。或者变量名忽略大小写后与key一样的变量。如HIgh，Class。第一个匹配的就赋值，后面就算有匹配的也忽略。<br>
(前提是该变量必需是可导出的，即首字母大写)。<br>
不可导出的变量无法被解析（如sex变量，虽然json串中有key为sex的k-v，解析后其值仍为nil,即空值）</p>
<p>当接收体中存在json串中匹配不了的项时，解析会自动忽略该项，该项仍保留原值。如变量Test，保留空值nil。</p>
<p>你一定会发现，变量Class貌似没有解析为我们期待样子。因为此时的Class是个interface{}类型的变量，而json串中key为CLASS的value是个复合结构，不是可以直接解析的简单类型数据（如“张三”，18，true等）。所以解析时，由于没有指定变量Class的具体类型，json自动将value为复合结构的数据解析为map[string]interface{}类型的项。也就是说，此时的struct Class对象与StuRead中的Class变量没有半毛钱关系，故与这次的json解析没有半毛钱关系。</p>
<p>让我们看一下这几个interface{}变量解析后的类型</p>
<pre><code>func main() {
    //与前边json解析的代码一致
    ...
    fmt.Println(stu) //打印json解析前变量类型
    err:=json.Unmarshal(str,&amp;stu)
    fmt.Println(&quot;--------------json 解析后-----------&quot;)
    ... 
    fmt.Println(stu) //打印json解析后变量类型    
}

//利用反射，打印变量类型
func printType(stu *StuRead){
    nameType:=reflect.TypeOf(stu.Name)
    ageType:=reflect.TypeOf(stu.Age)
    highType:=reflect.TypeOf(stu.HIgh)
    sexType:=reflect.TypeOf(stu.sex)
    classType:=reflect.TypeOf(stu.Class)
    testType:=reflect.TypeOf(stu.Test)

    fmt.Println(&quot;nameType:&quot;,nameType)
    fmt.Println(&quot;ageType:&quot;,ageType)
    fmt.Println(&quot;highType:&quot;,highType)
    fmt.Println(&quot;sexType:&quot;,sexType)
    fmt.Println(&quot;classType:&quot;,classType)
    fmt.Println(&quot;testType:&quot;,testType)
}
</code></pre>
<p>结果：</p>
<pre><code>nameType: &lt;nil&gt;
ageType: &lt;nil&gt;
highType: &lt;nil&gt;
sexType: &lt;nil&gt;
classType: &lt;nil&gt;
testType: &lt;nil&gt;
--------------json 解析后-----------
nameType: string
ageType: float64
highType: bool
sexType: &lt;nil&gt;
classType: map[string]interface {}
testType: &lt;nil&gt;
</code></pre>
<p>从结果中可见</p>
<p>interface{}类型变量在json解析前，打印出的类型都为nil，就是没有具体类型，这是空接口（interface{}类型）的特点。</p>
<p>json解析后，json串中value，只要是”简单数据”，都会按照默认的类型赋值，如”张三”被赋值成string类型到Name变量中，数字18对应float64，true对应bool类型。</p>
<p>“简单数据”：是指不能再进行二次json解析的数据，如”name”:”张三”只能进行一次json解析。<br>
“复合数据”：类似”CLASS\”:{\”naME\”:\”1班\”,\”GradE\”:3}这样的数据，是可进行二次甚至多次json解析的，因为它的value也是个可被解析的独立json。即第一次解析key为CLASS的value，第二次解析value中的key为naME和GradE的value</p>
<p>对于”复合数据”，如果接收体中配的项被声明为interface{}类型，go都会默认解析成map[string]interface{}类型。如果我们想直接解析到struct Class对象中，可以将接受体对应的项定义为该struct类型。如下所示：</p>
<p>type StuRead struct {<br>
...<br>
//普通struct类型<br>
Class Class <code>json:&quot;class&quot;</code><br>
//指针类型<br>
Class *Class <code>json:&quot;class&quot;</code><br>
}</p>
<p>stu打印结果</p>
<p>Class类型：{张三 18 true <nil> {1班 3} <nil>}<br>
*Class类型：{张三 18 true <nil> 0xc42008a0c0 <nil>}</p>
<p>可以看出，传递Class类型的指针时，stu中的Class变量存的是指针，我们可通过该指针直接访问所属的数据，如stu.Class.Name/stu.Class.Grade</p>
<p>Class变量解析后类型</p>
<p>classType: main.Class<br>
classType: *main.Class<br>
解析时，如果接受体中同时存在2个匹配的项，会发生什么呢？<br>
测试1</p>
<p>type StuRead struct {<br>
NAme interface{}<br>
Name  interface{}<br>
NAMe interface{}    <code>json:&quot;name&quot;</code><br>
}<br>
结果1:</p>
<pre><code>//当存在匹配的json标签时，其对应的项被赋值。
//切记：匹配的标签可以没有，但有时最好只有一个哦
{&lt;nil&gt; &lt;nil&gt; 张三}
</code></pre>
<p>测试2</p>
<p>type StuRead struct {<br>
NAme interface{}<br>
Name  interface{}<br>
NAMe interface{}    <code>json:&quot;name&quot;</code><br>
NamE interface{}    <code>json:&quot;name&quot;</code><br>
}<br>
结果2</p>
<pre><code>//当匹配的json标签有多个时，标签对应的项都不会被赋值。
//忽略标签项，从上往下寻找第一个没有标签且匹配的项赋值
{张三 &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;}
</code></pre>
<p>测试3</p>
<p>type StuRead struct {<br>
NAme interface{}<br>
Name  interface{}<br>
}<br>
结果3</p>
<pre><code>//没有json标签时，从上往下，第一个匹配的项会被赋值哦
{张三 &lt;nil&gt;}
</code></pre>
<p>测试4</p>
<pre><code>type StuRead struct {
    NAMe interface{}    `json:&quot;name&quot;`
    NamE interface{}    `json:&quot;name&quot;`
}
</code></pre>
<p>结果4</p>
<pre><code>//当相同的json标签有多个，且没有不带标签的匹配项时，报错了哦
# command-line-arguments
src/test/b.go:48: stu.Name undefined (type *StuRead has no field or method Name, but does have NAMe)
</code></pre>
<p>可见，与前边说过的匹配规则是一致的。</p>
<p>如果不想指定Class变量为具体的类型，仍想保留interface{}类型，但又希望该变量可以解析到struct Class对象中，这时候该怎么办呢？</p>
<p>这种需求是很可能存在的，例如笔者我就碰到了</p>
<p>办法还是有的，我们可以将该变量定义为json.RawMessage类型</p>
<pre><code>type StuRead struct {
    Name  interface{}
    Age   interface{}
    HIgh  interface{}
    Class json.RawMessage `json:&quot;class&quot;` //注意这里
}

type Class struct {
    Name  string
    Grade int
}

func main() {
    data:=&quot;{\&quot;name\&quot;:\&quot;张三\&quot;,\&quot;Age\&quot;:18,\&quot;high\&quot;:true,\&quot;sex\&quot;:\&quot;男\&quot;,\&quot;CLASS\&quot;:{\&quot;naME\&quot;:\&quot;1班\&quot;,\&quot;GradE\&quot;:3}}&quot;
    str:=[]byte(data)
    stu:=StuRead{}
    _:=json.Unmarshal(str,&amp;stu)

    //注意这里：二次解析！
    cla:=new(Class)
    json.Unmarshal(stu.Class,cla)

    fmt.Println(&quot;stu:&quot;,stu)
    fmt.Println(&quot;string(stu.Class):&quot;,string(stu.Class))
    fmt.Println(&quot;class:&quot;,cla)
    printType(&amp;stu) //函数实现前面例子有
}
</code></pre>
<p>结果</p>
<pre><code>stu: {张三 18 true [123 34 110 97 77 69 34 58 34 49 231 143 173 34 44 34 71 114 97 100 69 34 58 51 125]}
string(stu.Class): {&quot;naME&quot;:&quot;1班&quot;,&quot;GradE&quot;:3}
class: &amp;{1班 3}
nameType: string
ageType: float64
highType: bool
classType: json.RawMessage
</code></pre>
<p>从结果中可见</p>
<p>接收体中，被声明为json.RawMessage类型的变量在json解析时，变量值仍保留json的原值，即未被自动解析为map[string]interface{}类型。如变量Class解析后的值为：{“naME”:”1班”,”GradE”:3}</p>
<p>从打印的类型也可以看出，在第一次json解析时，变量Class的类型是json.RawMessage。此时，我们可以对该变量进行二次json解析，因为其值仍是个独立且可解析的完整json串。我们只需再定义一个新的接受体即可，如json.Unmarshal(stu.Class,cla)</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[golang笔记-数组、切片、map]]></title>
        <id>http://lvelvis.github.io/post/golang-bi-ji-shu-zu-qie-pian-map/</id>
        <link href="http://lvelvis.github.io/post/golang-bi-ji-shu-zu-qie-pian-map/">
        </link>
        <updated>2020-05-26T05:29:04.000Z</updated>
        <content type="html"><![CDATA[<h1 id="数组">数组</h1>
<p>数组的长度一旦定义了就不能动态增长，并且存储的数据类型必须相同。</p>
<h2 id="创建方法">创建方法：</h2>
<p>var 数组名 [长度]数据类型<br>
例如：</p>
<pre><code>package main
import &quot;fmt&quot;
 
func main(){
    var test [5]int //定义数组名字test，长度为5，数据类型为int的数组
    test[0] = 1    //赋值
    test[1] = 2   
    test[2] = 3
    test[3] = 4
    fmt.Println(test) 
    fmt.Println(test[2])
    fmt.Println(test[1:3]) //输出1到3的数组
    fmt.Println(test[0:]) //0到结尾
    fmt.Println(test[:3])  //0到3
 
}
</code></pre>
<pre><code>##结果##
[1 2 3 4 0]
3
[2 3]
[1 2 3 4 0]
[1 2 3]
</code></pre>
<h2 id="数组的四种初始化方式">数组的四种初始化方式</h2>
<p>例如：</p>
<pre><code>var s1 [3]int = [3]int{1,2,3}
fmt.Println(&quot;s1&quot;,s1)
var s2 [4]int = [...]int{5,6,7,8} //[...]是固定写法
fmt.Println(&quot;s2&quot;,s2)
var s3 = [2]int{9,10} //第一种的简化
fmt.Println(&quot;s3&quot;,s3)
var s4 = [...]int{3:43,1:41,0:40,2:42} //类似键值对
fmt.Println(&quot;s4&quot;,s4)
var s5 = new([5]int)
s5[4] =12
fmt.Println(&quot;s5&quot;,s5)
</code></pre>
<pre><code>##结果##
s1 [1 2 3]
s2 [5 6 7 8]
s3 [9 10]
s4 [40 41 42 43]
s5 [0 0 0 0 5]
</code></pre>
<h2 id="数组的遍历">数组的遍历</h2>
<p>例如：</p>
<pre><code>var s4 = [...]int{3:43,1:41,0:40,2:42} //类似键值对
fmt.Println(&quot;s4&quot;,s4)
     
for index,value := range s4{
fmt.Println(index,value)
}
 
#结果##
0 40
1 41
2 42
3 43
</code></pre>
<pre><code>var s4 = [...]int{3:43,1:41,0:40,2:42} //类似键值对
for i := 0;i &lt;len(s4);i++{
fmt.Println(i,s4[i])
}
 
#结果##
0 40
1 41
2 42
3 43
</code></pre>
<h1 id="slice切片">slice切片</h1>
<p>1、切片是数组的引用(切片是数组的一部分)<br>
2、切片的使用类似数组，如遍历<br>
3、切片的长度是可变的</p>
<h2 id="创建语法">创建语法</h2>
<p>var 切片名 []类型<br>
如：</p>
<pre><code>var qiepian []int
</code></pre>
<h2 id="切片示例">切片示例:</h2>
<pre><code>###例子一&lt;br&gt;var suzhu [4]int = [...]int{5,6,7,8}
slice := suzhu[1:4] //1到4的值，不包含4
fmt.Println(suzhu)
fmt.Println(slice)
fmt.Println(&quot;切片的容量&quot;,cap(slice))
 
##结果
[5 6 7 8]
[6 7 8]
切片的容量 3&lt;br&gt;&lt;br&gt;
###例子二、使用make创建切片
var slice []int = make([]int,4,10) //类型，大小(长度),容量（可选），容量必须大于长度
slice[0] = 10
slice[1] = 11
fmt.Println(slice)
 
##结果##
[10 11 0 0]
 
 
###例子三
var slice []int = []int {2,4,6}
fmt.Println(slice)
 
##结果##
2 4 6
</code></pre>
<h2 id="切片的append追加">切片的append追加</h2>
<p>例如：</p>
<pre><code>var slice []int = []int {2,4,6}
fmt.Println(slice)
//使用append直接追加切片内容（类似python list的append）
slice = append(slice,8,10)
fmt.Println(slice)
slice = append(slice,slice...) //追加切片，...是固定写法
fmt.Println(slice)
 
###结果###
[2 4 6]
[2 4 6 8 10]
[2 4 6 8 10 2 4 6 8 10]
</code></pre>
<h2 id="切片的copy操作">切片的copy操作</h2>
<p>使用copy内置函数<br>
例如:</p>
<pre><code>var slice []int = []int {2,4,6}
fmt.Println(slice)
var slice2 []int = make([]int,5)
fmt.Println(slice2)
copy(slice2,slice) //将slice复制给slice2
fmt.Println(slice)
fmt.Println(slice2)
 
##结果##
[2 4 6]
[0 0 0 0 0]
[2 4 6]
[2 4 6 0 0]
</code></pre>
<h2 id="使用切片改变字符串的内容">使用切片改变字符串的内容</h2>
<pre><code>var str string = &quot;hello&quot;
fmt.Println(str)
arr := []byte(str)
arr[1] = 'a' //转成字符串
arr1 := []rune(str) //中文转换
arr1[0] = '狗'
fmt.Println(arr)
str = string(arr)
fmt.Println(str)
str = string(arr1)
fmt.Println(str)
 
##结果##
hello
[104 97 108 108 111]
hello
狗hello
</code></pre>
<h1 id="map">map</h1>
<p>map是key-value数据结构(类似python的dict)<br>
map是无序存储的</p>
<p>创建map语法<br>
var map 变量名 map[keytype]valuetype</p>
<p>如：</p>
<pre><code>var m1 map[string]string
var m2 map[string]int
var m3 map[int]string
var m4 map[string]map[string]string
```　　

使用例子：
</code></pre>
<p>package main<br>
import &quot;fmt&quot;</p>
<p>func main(){<br>
var m1 map[string]string<br>
//在使用map前,需要先make，make的作用技术给map分配数据空间<br>
m1 = make(map[string]string)<br>
m2 := map[string]string{  //使用方式二<br>
&quot;a1&quot; : &quot;q1&quot;,<br>
&quot;a2&quot; : &quot;a2&quot;,<br>
}<br>
m1[&quot;s1&quot;] = &quot;亚索&quot;<br>
m1[&quot;s2&quot;] = &quot;盖伦&quot;<br>
fmt.Println(m1)<br>
fmt.Println(m1[&quot;s1&quot;])<br>
fmt.Println(m2)<br>
}</p>
<p>###结果###<br>
map[s1:亚索 s2:盖伦]<br>
亚索<br>
map[a1:q1 a2:a2]</p>
<pre><code>
 

map的增删改查
增、改
map[key] = value //没有就增加，存在就修改

删
delete(map,key)

查
map[key]   //对应的value，和python的dict一样</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s hpa弹性扩容配置]]></title>
        <id>http://lvelvis.github.io/post/k8s-hpa-dan-xing-kuo-rong-pei-zhi/</id>
        <link href="http://lvelvis.github.io/post/k8s-hpa-dan-xing-kuo-rong-pei-zhi/">
        </link>
        <updated>2020-05-19T05:24:13.000Z</updated>
        <content type="html"><![CDATA[<pre><code>HPA全称Horizontal Pod Autoscaling，是K8s实现pod自动水平扩容缩容的特性，这个特性使整个kubernetes集群马上高大上起来了。
要使用HPA也不是这么简单的，HPA api分v1、v2beta1、v2bate2三种，v1只支持通过CPU衡量扩缩容，v2bate1加入针对内存作为度量，v2bate2可以用customer metrics例如网络等，所以v2bate1开始才比较实用。
</code></pre>
<p>要使用HPA必须要开启以下两个特性：</p>
<p>Aggregation Layer 聚合层，通过与核心的apiserver分离，实现自定义的扩展功能<br>
metrics-server 数据收集，能够收集pod、node等实时运行指标（cpu、内存），给k8s集群使用，例如kubectl top命令、HPA<br>
比较老的版本使用heapster</p>
<h1 id="aggregation-layer">Aggregation Layer</h1>
<p>要打开Aggregation Layer，需要配置一下apiserver，增加相关认证证书。认证流程是client发起请求到apiserver，apiserver与aggergated apiserver建立tls安全链接，把请求proxy到aggergated apiserver，继续进行–requestheader-*参数的相关认证。</p>
<p>认证流程<br>
<img src="http://lvelvis.github.io/post-images/1589865988979.png" alt="" loading="lazy"></p>
<p>需要生成aggregate使用的证书，参考cfssl生成证书方法，proxy-client-cert-file的CN需要与requestheader-allowed-names匹配。<br>
在apiserver增加如下启动参数</p>
<pre><code>--requestheader-client-ca-file=/etc/kubernetes/pki/agg-ca.pem
--proxy-client-cert-file=/etc/kubernetes/pki/aggregate.pem
--proxy-client-key-file=/etc/kubernetes/pki/aggregate-key.pem
--requestheader-allowed-names=aggregator
--requestheader-extra-headers-prefix=X-Remote-Extra-
--requestheader-group-headers=X-Remote-Group
--requestheader-username-headers=X-Remote-User
#如果kube-proxy没有在Master上面运行，还需要配置
--enable-aggregator-routing=true
</code></pre>
<h1 id="metrics-server">metrics server</h1>
<p>从k8s 1.8开始，集群的资源使用情况都通过metrics api收集，例如容器CPU、内存。这些指标可用于kuberctl top或者k8s的HPA等特性。<br>
metrice server可以在github找到并部署</p>
<pre><code>git clone https://github.com/kubernetes-incubator/metrics-server
cd metrics-server
kubectl create -f deploy/1.8+/
</code></pre>
<pre><code>注1：metrics-server默认使用node的主机名，但是coredns里面没有物理机主机名的解析，一种是部署的时候添加一个参数： –kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP,第二种是使用dnsmasq构建一个上游的dns服务
注2：kubelet 的10250端口使用的是https协议，连接需要验证tls证书。可以在metrics server启动命令添加参数–kubelet-insecure-tls不验证客户端证书
注3：yaml文件中的image地址k8s.gcr.io/metrics-server-amd64:v0.3.3 需要梯子，需要改成中国可以访问的image地址，可以使用aliyun的。这里使用hub.docker.com里的google镜像地址 image: mirrorgooglecontainers/metrics-server-amd64:v0.3.3
</code></pre>
<p>成功运行kubectl top命令</p>
<pre><code>ubuntu@k8s-dev-m1:~/k8sssl/agglayer$ kubectl top nodes
NAME                   CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-dev-node2          103m         5%      2696Mi                 72%       
k8s-dev-node3.bxr.cn   115m      2%     5312Mi                  67%  
k8s-dev-node4          57m          2%       2634Mi                  70%     
k8s-dev-node5          148m         7%       2443Mi                  65%
</code></pre>
<h1 id="hpa">HPA</h1>
<pre><code>有了metrics就可以开始使用HPA特性了。hpa有几个特点
deploy或者rs等需要设置resources才能使用hpa
如果我们创建一个HPA controller，它会每隔15s（可以通过–horizontal-pod-autoscaler-sync-period修改）检测一次hpa定义的资源与实际资源使用情况，如果达到阀值就会调整pod数量。
HPA设置的阀值不是绝对的，允许设置一个浮动范围，–horizontal-pod-autoscaler-tolerance默认是0.1
pod调整算法 desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]
scale有一个窗口期，期间每次变化会记录下来，选择最优的调整建议再进行scale，这样可以保证资源平滑变动，通过–horizontal-pod-autoscaler-downscale-stabilization设定，默认5分钟。
通过hpa调整新增的pod不会马上ready，这时候收集的metrics就不准，为了减少影响，hpa一开始不会收集新pod的metrics。通过–horizontal-pod-autoscaler-initial-readiness-delay（默认30s）和 –horizontal-pod-autoscaler-cpu-initialization-period（默认为 5 分钟）调整
</code></pre>
<p><img src="http://lvelvis.github.io/post-images/1589866316410.svg" alt="" loading="lazy"><br>
示例hpa.yml:</p>
<pre><code>apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-test
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: podinfo
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization 
        averageUtilization: 160
</code></pre>
<p>上面的示例包括cpu和memory指标，averageUtilization这个百分比是根据deployment的resources.requests计算的。例如有deployment限制requests是512Mi，replicas是2，实际pod1用了612Mi，pod2用了598Mi，计算公式是 (612+598)/2/512 = 118%</p>
<p>查看hpa的情况，targets第一个是memory，第二个是cpu指标，REPLICAS是根据计算后的当前pod数</p>
<pre><code>ubuntu@k8s-m1:~/k8s/hpa$ kubectl get hpa
NAME       REFERENCE            TARGETS             MINPODS   MAXPODS   REPLICAS   AGE
hpa-test   Deployment/podinfo   120%/160%, 6%/75%   2         4         3          97m
</code></pre>
<p>官方示例还包括packets-per-second、requests-per-second这些指标，需要进一步验证</p>
<pre><code>apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: AverageUtilization
        averageUtilization: 50
  - type: Pods
    pods:
      metric:
        name: packets-per-second
      targetAverageValue: 1k
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1beta1
        kind: Ingress
        name: main-route
      target:
        kind: Value
        value: 10k
status:
  observedGeneration: 1
  lastScaleTime: &lt;some-time&gt;
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
    current:
      averageUtilization: 0
      averageValue: 0
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1beta1
        kind: Ingress
        name: main-route
      current:
        value: 10k

</code></pre>
<p><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#create-horizontal-pod-autoscaler">官方hpa参数</a></p>
]]></content>
    </entry>
</feed>