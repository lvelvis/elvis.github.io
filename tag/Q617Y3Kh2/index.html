<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="lvelvis个人博客">
<meta name="description" content="时光,浓淡相宜;人心,远近相安;这就是最好的生活">
<meta name="theme-color" content="#000">
<title>lvelvis</title>
<link rel="shortcut icon" href="/favicon.ico?v=1588221131328">
<link rel="stylesheet" href="/styles/main.css">
<link rel="stylesheet" href="/media/css/mist.css">

<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/androidstudio.css"
  rel="stylesheet">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="mist">
  <header class="header bg-color ">
    <div class="blog-header box-shadow-wrapper  " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="">
              <span class="logo-line-before">
                <i class=""></i>
              </span>
              <span class="main-title">lvelvis</span>
              <span class="logo-line-after">
                <i class=""></i>
              </span>
            </a>  
          
        </div>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout bg-color mist">
      <div class="section-layout-wrapper">
        <div id="sidebarMeta" class="sidebar">
    
<div class="sidebar-wrapper box-shadow-wrapper ">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">lvelvis</p>
    
    <div class="site-description right-motion">
      
        <p id="binft">时光,浓淡相宜;人心,远近相安;这就是最好的生活</p>
      
    </div>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">2</span>
        <span class="site-item-stat-name">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">4</span>
        <span class="site-item-stat-name">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">4</span>
        <span class="site-item-stat-name">标签</span>
      </a>
    </div>
  </div>
  
  
    <div class="sidebar-item sidebar-item-social">
      <div class="social-item">
        
          
            <a href="https://github.com/lvelvis">
              <i class="fa fa-github-alt" title="github"></i>
            </a>
          
            <a href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=421220622&amp;website=www.oicqzone.com&#34;&gt;">
              <i class="fa fa-qq" title="QQ"></i>
            </a>
          
        
        
          
            <a class="social-img" href="#">
              <img src="\media\images\custom-array-imgSocials-1588146527513-socialImg.jpg" />
              <i class="fa fa-wechat" title="weixin" ></i>
            </a>
          
        
      </div>
    </div>
  


</div>
</div>
<script>
  let sidebarMeta = document.querySelector('#sidebarMeta');
  let scheme = 'mist';
  let sidebarWrapper = document.querySelector('.sidebar-wrapper');
  if (sidebarMeta && (scheme === 'pisces' || scheme === 'gemini')) {
    document.addEventListener('scroll', function(e) {
      if (document.scrollingElement.scrollTop > parseInt(sidebarMeta.style.marginTop) + 10) {
        sidebarWrapper.classList.add('home-sidebar-fixed')
      } else {
        sidebarWrapper.classList.remove('home-sidebar-fixed')
      }
    });
  }
  </script>
        <div class="section-box tag-line box-shadow-wrapper">
          <section class="section tags-section posts-expand bg-color">
            <div class="padding-wrapper">
  <div class="tag-timeline-box">
    <div class="tag-timeline-wrapper">
      <div class="tag-timeline-title">
        <h2>
          k8s
          <small>标签</small>
        </h2>
      </div>
      
      
      
      
      
      <a href="https://lvelvis.github.io/post/kubesphere-an-zhuang-shi-yong-ti-yan/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              04-29
              <small>kubesphere安装使用体验</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      <a href="https://lvelvis.github.io/post/kubernetes搭建rook-ceph/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              12-12
              <small>kubernetes搭建rook-ceph</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
    </div>
  </div>
</div>
          </section>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2020 Theme By elvis</a>
    </div>
    <div class="poweredby">
      
    </div>
  </footer>
  
  
    <div class="drawer-box left" id="drawer_box">
      <span class="muse-line muse-line-first"></span>
      <span class="muse-line muse-line-middle"></span>
      <span class="muse-line muse-line-last"></span>
    </div>
  
  <div class="mist back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
  </div>
  
  
    
<link rel="stylesheet" href="/media/live2d/css/live2d.css" />
<div class="box-scale">
  <div id="landlord" style="left: 5px;bottom: px;"
    data-key="">
    <canvas id="live2d" width="500" height="560" class="live2d"></canvas>
    

      <div class="message" style="opacity:0"></div>
      <div class="live_talk_input_body">
        <div class="live_talk_input_name_body">
          <input name="name" type="text" class="live_talk_name white_input" id="AIuserName" autocomplete="off"
            placeholder="你的名字" />
        </div>
        <div class="live_talk_input_text_body">
          <input name="talk" type="text" class="live_talk_talk white_input" id="AIuserText" autocomplete="off"
            placeholder="要和我聊什么呀？" />
          <button type="button" class="live_talk_send_btn" id="talk_send">发送</button>
        </div>
      </div>
      <input name="live_talk" id="live_talk" value="1" type="hidden" />
      <div class="live_ico_box">
        <div class="live_ico_item type_info" id="showInfoBtn"></div>
        <div class="live_ico_item type_talk" id="showTalkBtn"></div>
        
        <div class="live_ico_item type_music" id="musicButton"></div>
        
        <div class="live_ico_item type_youdu" id="youduButton"></div>
        <div class="live_ico_item type_quit" id="hideButton"></div>
        <input name="live_statu_val" id="live_statu_val" value="0" type="hidden" />
        <audio src="" style="display:none;" id="live2d_bgm" data-bgm="0" preload="none"></audio>
        <input id="duType" value="douqilai" type="hidden">
        
        <input name="live2dBGM" value="" type="hidden">
        
      </div>
    
  </div>
</div>
<div id="open_live2d">召唤看板娘</div>
<script src="https://libs.baidu.com/jquery/2.0.0/jquery.min.js"></script>
<script>
  var message_Path = 'https://cdn.jsdelivr.net/gh/hsxyhao/live2d.github.io@master/';
  let landlord = document.querySelector('#landlord');
  var apiKey = landlord.dataset.key;
</script>
<script type="text/javascript" src="/media/live2d/js/live2d.js"></script>
<script>
	var home_Path = document.location.protocol + '//' + window.document.location.hostname + ":" + window.document.location.port + '/';
	var userAgent = window.navigator.userAgent.toLowerCase();
	var norunAI = ["android", "iphone", "ipod", "ipad", "windows phone", "mqqbrowser", "msie", "trident/7.0"];
	var norunFlag = false;

	for (var i = 0; i < norunAI.length; i++) {
		if (userAgent.indexOf(norunAI[i]) > -1) {
			norunFlag = true;
			break;
		}
	}

	if (!window.WebGLRenderingContext) {
		norunFlag = true;
	}

	if (!norunFlag) {
		var hitFlag = false;
		var AIFadeFlag = false;
		var liveTlakTimer = null;
		var sleepTimer_ = null;
		var AITalkFlag = false;
		var talkNum = 0;
		(function () {
			function renderTip(template, context) {
				var tokenReg = /(\\)?\{([^\{\}\\]+)(\\)?\}/g;
				return template.replace(tokenReg, function (word, slash1, token, slash2) {
					if (slash1 || slash2) {
						return word.replace('\\', '');
					}
					var variables = token.replace(/\s/g, '').split('.');
					var currentObject = context;
					var i, length, variable;
					for (i = 0, length = variables.length; i < length; ++i) {
						variable = variables[i];
						currentObject = currentObject[variable];
						if (currentObject === undefined || currentObject === null) return '';
					}
					return currentObject;
				});
			}

			String.prototype.renderTip = function (context) {
				return renderTip(this, context);
			};

			var re = /x/;
			re.toString = function () {
				showMessage('哈哈，你打开了控制台，是想要看看我的秘密吗？', 5000);
				return '';
			};

			$(document).on('copy', function () {
				showMessage('你都复制了些什么呀，转载要记得加上出处哦~~', 5000);
			});

			function initTips() {
				$.ajax({
					cache: true,
					url: message_Path + 'message.json',
					dataType: "json",
					success: function (result) {
						$.each(result.mouseover, function (index, tips) {
							$(tips.selector).mouseover(function () {
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
								talkValTimer();
								clearInterval(liveTlakTimer);
								liveTlakTimer = null;
							});
							$(tips.selector).mouseout(function () {
								showHitokoto();
								if (liveTlakTimer == null) {
									liveTlakTimer = window.setInterval(function () {
										showHitokoto();
									}, 15000);
								};
							});
						});
						$.each(result.click, function (index, tips) {
							$(tips.selector).click(function () {
								if (hitFlag) {
									return false
								}
								hitFlag = true;
								setTimeout(function () {
									hitFlag = false;
								}, 8000);
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
							});
							clearInterval(liveTlakTimer);
							liveTlakTimer = null;
							if (liveTlakTimer == null) {
								liveTlakTimer = window.setInterval(function () {
									showHitokoto();
								}, 15000);
							};
						});
					}
				});
			}
			initTips();

			var text;
			if (document.referrer !== '') {
				var referrer = document.createElement('a');
				referrer.href = document.referrer;
				text = '嗨！来自 <span style="color:#0099cc;">' + referrer.hostname + '</span> 的朋友！';
				var domain = referrer.hostname.split('.')[1];
				if (domain == 'baidu') {
					text = '嗨！ 来自 百度搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'so') {
					text = '嗨！ 来自 360搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'google') {
					text = '嗨！ 来自 谷歌搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			} else {
				if (window.location.href == home_Path) { //主页URL判断，需要斜杠结尾
					var now = (new Date()).getHours();
					if (now > 23 || now <= 5) {
						text = '你是夜猫子呀？这么晚还不睡觉，明天起的来嘛？';
					} else if (now > 5 && now <= 7) {
						text = '早上好！一日之计在于晨，美好的一天就要开始了！';
					} else if (now > 7 && now <= 11) {
						text = '上午好！工作顺利嘛，不要久坐，多起来走动走动哦！';
					} else if (now > 11 && now <= 14) {
						text = '中午了，工作了一个上午，现在是午餐时间！';
					} else if (now > 14 && now <= 17) {
						text = '午后很容易犯困呢，今天的运动目标完成了吗？';
					} else if (now > 17 && now <= 19) {
						text = '傍晚了！窗外夕阳的景色很美丽呢，最美不过夕阳红~~';
					} else if (now > 19 && now <= 21) {
						text = '晚上好，今天过得怎么样？';
					} else if (now > 21 && now <= 23) {
						text = '已经这么晚了呀，早点休息吧，晚安~~';
					} else {
						text = '嗨~ 快来逗我玩吧！';
					}
				} else {
					text = '欢迎阅读<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			}
			showMessage(text, 12000);
		})();

		liveTlakTimer = setInterval(function () {
			showHitokoto();
		}, 15000);

		function showHitokoto() {
			if (sessionStorage.getItem("Sleepy") !== "1") {
				if (!AITalkFlag) {
					$.getJSON('https://v1.hitokoto.cn/', function (result) {
						talkValTimer();
						showMessage(result.hitokoto, 0);
					});
				}
			} else {
				hideMessage(0);
				if (sleepTimer_ == null) {
					sleepTimer_ = setInterval(function () {
						checkSleep();
					}, 200);
				}
			}
		}

		function checkSleep() {
			var sleepStatu = sessionStorage.getItem("Sleepy");
			if (sleepStatu !== '1') {
				talkValTimer();
				showMessage('你回来啦~', 0);
				clearInterval(sleepTimer_);
				sleepTimer_ = null;
			}
		}

		function showMessage(text, timeout) {
			if (Array.isArray(text)) text = text[Math.floor(Math.random() * text.length + 1) - 1];
			$('.message').stop();
			$('.message').html(text);
			$('.message').fadeTo(200, 1);
			//if (timeout === null) timeout = 5000;
			//hideMessage(timeout);
		}
		function talkValTimer() {
			$('#live_talk').val('1');
		}

		function hideMessage(timeout) {
			//$('.message').stop().css('opacity',1);
			if (timeout === null) timeout = 5000;
			$('.message').delay(timeout).fadeTo(200, 0);
		}

		function initLive2d() {
			$('#hideButton').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "0");
					$('#landlord').fadeOut(200);
					$('#open_live2d').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#open_live2d').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "1");
					$('#open_live2d').fadeOut(200);
					$('#landlord').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#youduButton').on('click', function () {
				if ($('#youduButton').hasClass('doudong')) {
					var typeIs = $('#youduButton').attr('data-type');
					$('#youduButton').removeClass('doudong');
					$('body').removeClass(typeIs);
					$('#youduButton').attr('data-type', '');
				} else {
					var duType = $('#duType').val();
					var duArr = duType.split(",");
					var dataType = duArr[Math.floor(Math.random() * duArr.length)];

					$('#youduButton').addClass('doudong');
					$('#youduButton').attr('data-type', dataType);
					$('body').addClass(dataType);
				}
			});
			if (apiKey) {
				$('#showInfoBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "0") {
						return
					} else {
						$('#live_statu_val').val("0");
						$('.live_talk_input_body').fadeOut(500);
						AITalkFlag = false;
						showHitokoto();
						$('#showTalkBtn').show();
						$('#showInfoBtn').hide();
					}
				});
				$('#showTalkBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "1") {
						return
					} else {
						$('#live_statu_val').val("1");
						$('.live_talk_input_body').fadeIn(500);
						AITalkFlag = true;
						$('#showTalkBtn').hide();
						$('#showInfoBtn').show();

					}
				});
				$('#talk_send').on('click', function () {
					var info_ = $('#AIuserText').val();
					var userid_ = $('#AIuserName').val();
					if (info_ == "") {
						showMessage('写点什么吧！', 0);
						return;
					}
					if (userid_ == "") {
						showMessage('聊之前请告诉我你的名字吧！', 0);
						return;
					}
					showMessage('思考中~', 0);
					let protocol = window.location.protocol.indexOf("s") > 0 ? "https" : "http";
					$.ajax({
						type: "get",
						url: `${protocol}://www.tuling123.com/openapi/api?key=${apiKey}&info=${info_}`,
						dataType: "json",
						success: function (res) {
							talkValTimer();
							showMessage(res.text, 0);
							$('#AIuserText').val("");
							sessionStorage.setItem("live2duser", userid_);
						},
						error: function (e) {
							talkValTimer();
							showMessage('似乎有什么错误，请和站长联系！', 0);
						}
					});
				});
			} else {
				$('#showInfoBtn').hide();
				$('#showTalkBtn').hide();
			}
			//获取音乐信息初始化
			var bgmListInfo = $('input[name=live2dBGM]');
			if (bgmListInfo.length == 0) {
				$('#musicButton').hide();
			} else {
				var bgmPlayNow = parseInt($('#live2d_bgm').attr('data-bgm'));
				var bgmPlayTime = 0;
				var live2dBGM_Num = sessionStorage.getItem("live2dBGM_Num");
				var live2dBGM_PlayTime = sessionStorage.getItem("live2dBGM_PlayTime");
				if (live2dBGM_Num) {
					if (live2dBGM_Num <= $('input[name=live2dBGM]').length - 1) {
						bgmPlayNow = parseInt(live2dBGM_Num);
					}
				}
				if (live2dBGM_PlayTime) {
					bgmPlayTime = parseInt(live2dBGM_PlayTime);
				}
				var live2dBGMSrc = bgmListInfo.eq(bgmPlayNow).val();
				$('#live2d_bgm').attr('data-bgm', bgmPlayNow);
				$('#live2d_bgm').attr('src', live2dBGMSrc);
				$('#live2d_bgm')[0].currentTime = bgmPlayTime;
				$('#live2d_bgm')[0].volume = 0.5;
				var live2dBGM_IsPlay = sessionStorage.getItem("live2dBGM_IsPlay");
				var live2dBGM_WindowClose = sessionStorage.getItem("live2dBGM_WindowClose");
				if (live2dBGM_IsPlay == '0' && live2dBGM_WindowClose == '0') {
					$('#live2d_bgm')[0].play();
					$('#musicButton').addClass('play');
				}
				sessionStorage.setItem("live2dBGM_WindowClose", '1');
				$('#musicButton').on('click', function () {
					if ($('#musicButton').hasClass('play')) {
						$('#live2d_bgm')[0].pause();
						$('#musicButton').removeClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '1');
					} else {
						$('#live2d_bgm')[0].play();
						$('#musicButton').addClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				});
				window.onbeforeunload = function () {
					sessionStorage.setItem("live2dBGM_WindowClose", '0');
					if ($('#musicButton').hasClass('play')) {
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				}
				document.getElementById('live2d_bgm').addEventListener("timeupdate", function () {
					var live2dBgmPlayTimeNow = document.getElementById('live2d_bgm').currentTime;
					sessionStorage.setItem("live2dBGM_PlayTime", live2dBgmPlayTimeNow);
				});
				document.getElementById('live2d_bgm').addEventListener("ended", function () {
					var listNow = parseInt($('#live2d_bgm').attr('data-bgm'));
					listNow++;
					if (listNow > $('input[name=live2dBGM]').length - 1) {
						listNow = 0;
					}
					var listNewSrc = $('input[name=live2dBGM]').eq(listNow).val();
					sessionStorage.setItem("live2dBGM_Num", listNow);
					$('#live2d_bgm').attr('src', listNewSrc);
					$('#live2d_bgm')[0].play();
					$('#live2d_bgm').attr('data-bgm', listNow);
				});
				document.getElementById('live2d_bgm').addEventListener("error", function () {
					$('#live2d_bgm')[0].pause();
					$('#musicButton').removeClass('play');
					showMessage('音乐似乎加载不出来了呢！', 0);
				});
			}
			//获取用户名
			var live2dUser = sessionStorage.getItem("live2duser");
			if (live2dUser !== null) {
				$('#AIuserName').val(live2dUser);
			}
			//获取位置
			var landL = sessionStorage.getItem("historywidth");
			var landB = sessionStorage.getItem("historyheight");
			if (landL == null || landB == null) {
				landL = '5px'
				landB = '0px'
			}
			$('#landlord').css('left', landL + 'px');
			$('#landlord').css('bottom', landB + 'px');
			//移动
			function getEvent() {
				return window.event || arguments.callee.caller.arguments[0];
			}
			var smcc = document.getElementById("landlord");
			var moveX = 0;
			var moveY = 0;
			var moveBottom = 0;
			var moveLeft = 0;
			var moveable = false;
			var docMouseMoveEvent = document.onmousemove;
			var docMouseUpEvent = document.onmouseup;
			smcc.onmousedown = function () {
				var ent = getEvent();
				moveable = true;
				moveX = ent.clientX;
				moveY = ent.clientY;
				var obj = smcc;
				moveBottom = parseInt(obj.style.bottom);
				moveLeft = parseInt(obj.style.left);
				if (isFirefox = navigator.userAgent.indexOf("Firefox") > 0) {
					window.getSelection().removeAllRanges();
				}
				document.onmousemove = function () {
					if (moveable) {
						var ent = getEvent();
						var x = moveLeft + ent.clientX - moveX;
						var y = moveBottom + (moveY - ent.clientY);
						obj.style.left = x + "px";
						obj.style.bottom = y + "px";
					}
				};
				document.onmouseup = function () {
					if (moveable) {
						var historywidth = obj.style.left;
						var historyheight = obj.style.bottom;
						historywidth = historywidth.replace('px', '');
						historyheight = historyheight.replace('px', '');
						sessionStorage.setItem("historywidth", historywidth);
						sessionStorage.setItem("historyheight", historyheight);
						document.onmousemove = docMouseMoveEvent;
						document.onmouseup = docMouseUpEvent;
						moveable = false;
						moveX = 0;
						moveY = 0;
						moveBottom = 0;
						moveLeft = 0;
					}
				};
			};
		}
		$(document).ready(function () {
			var AIimgSrc = [];
			let chooseLive2d = 'hijiki'
			if (chooseLive2d === 'histoire') {
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_00.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_01.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_02.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_03.png");
			} else if (chooseLive2d === 'rem') {
				AIimgSrc.push(message_Path + "model/rem/remu2048/texture_00.png");
			} else if (chooseLive2d === 'Aoba') {
				AIimgSrc.push(message_Path + "model/Aoba/textures/texture_00.png");
			} else if (chooseLive2d === 'hijiki') {
				AIimgSrc.push(message_Path + "model/hijiki/moc/hijiki.2048/texture_00.png");
			} else if (chooseLive2d === 'tororo') {
				AIimgSrc.push(message_Path + "model/tororo/moc/tororo.2048/texture_00.png");
			}
			var images = [];
			var imgLength = AIimgSrc.length;
			var loadingNum = 0;
			for (var i = 0; i < imgLength; i++) {
				images[i] = new Image();
				images[i].src = AIimgSrc[i];
				images[i].onload = function () {
					loadingNum++;
					if (loadingNum === imgLength) {
						var live2dhidden = localStorage.getItem("live2dhidden");
						if (live2dhidden === "0") {
							setTimeout(function () {
								$('#open_live2d').fadeIn(200);
							}, 1300);
						} else {
							setTimeout(function () {
								$('#landlord').fadeIn(200);
							}, 1300);
						}
						let model = '';
						if (chooseLive2d === 'histoire') {
							model = message_Path + "model/histoire/model.json";
						} else if (chooseLive2d === 'rem') {
							model = message_Path + "model/rem/model.json";
						} else if (chooseLive2d === 'Aoba') {
							model = message_Path + "model/Aoba/model.json";
						} else if (chooseLive2d === 'hijiki') {
							model = message_Path + "model/hijiki/hijiki.model.json";
						} else if (chooseLive2d === 'tororo') {
							model = message_Path + "model/tororo/tororo.model.json";
						}
						setTimeout(function () {
							loadlive2d("live2d", model);
						}, 1000);
						initLive2d();
						images = null;
					}
				}
			}
		});
	}
</script>
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
  back2TopText = document.querySelector('#back_to_top_text'),
  drawerBox = document.querySelector('#drawer_box'),
  rightSideBar = document.querySelector('.sidebar'),
  viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {
   
    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function(e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });
  
  window.addEventListener('scroll', function(e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });

  
  let hasCacu = false;
  window.onresize = function() {
    if (window.width > 991) {
      calcuHeight();
    } else {
      hasCacu = false;
    }
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();
  
  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function() {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, transitionDir,{ });
          }
        })
        window.Velocity(viewport, openProp,{
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp ,{
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target","_blank");
      }
    })
  }
  // 代码高亮
  hljs.initHighlightingOnLoad();

</script>
  </div>
</body>
<input hidden id="copy" />
<script>
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        console.log('复制操作频率过高');
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })
</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 500
  });
</script>

<!-- <div class="search-mask" id="search_mask">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input type="text" placeholder="搜索">
      </div>
      <i class="fa fa-times-circle"></i>
    </div>
    <div class="result">
      
      <div class="item">
        <a class="result-title" href="https://lvelvis.github.io/post/kubesphere-an-zhuang-shi-yong-ti-yan/"" data-c="
          &lt;p&gt;最近又出来个kubesphere的工具用来管理k8s，今天特意来安装体验下；&lt;br&gt;
github地址：https://github.com/pixiake/ks-installer&lt;/p&gt;
&lt;p&gt;官方使用文档：https://kubesphere.io/docs/advanced-v2.0/zh-CN/installation/all-in-one/&lt;/p&gt;
&lt;p&gt;先放上安装效果图，UI界面还是很清爽的：&lt;br&gt;
&lt;img src=&#34;https://lvelvis.github.io/post-images/1588152934567.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;当前环境&#34;&gt;当前环境：&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;k8s集群已经安装完成，用kubesphere管理现有的k8s集群；

k8s版本为1.14

系统为centos7.6

kubesphere使用要求：

kubernetes version &amp;gt; 1.13.0

helm version &amp;gt; 2.10.0

a default storage class must be in kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;安装完成后默认用户名密码：&lt;/p&gt;
&lt;p&gt;用户名：admin&lt;/p&gt;
&lt;p&gt;密码：P@88w0rd&lt;/p&gt;
&lt;h3 id=&#34;开始安装&#34;&gt;开始安装&lt;/h3&gt;
&lt;p&gt;安装步骤大概记录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create ns kubesphere-system
kubectl create ns kubesphere-monitoring-system

#访问etcd用到的secret
kubectl -n kubesphere-monitoring-system create secret generic kube-etcd-client-certs  --from-file=etcd-client-ca.crt=ca.pem  --from-file=etcd-client.crt=etcd-key.pem  --from-file=etcd-client.key=etcd.pem

#管理k8s用到的secret

kubectl -n kubesphere-system create secret generic kubesphere-ca  --from-file=ca.crt=ca.pem --from-file=ca.key=ca-key.pem

#clone好github项目，执行下面的这条命令

cd deploy
kubectl apply -f kubesphere-installer.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行完上面的命令，可以通过下面的命令，查看安装过程日志&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l job-name=kubesphere-installer -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -f
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看安装结果，STATUS跟下面保持一致才说明安装成功&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@ks-allinone deploy]# kubectl get pods -n kubesphere-system
NAME                                     READY   STATUS      RESTARTS   AGE
ks-account-6db466d8dc-srrwj              1/1     Running     0          149m
ks-apigateway-7d77cb9495-jzmg6           1/1     Running     0          170m
ks-apiserver-f8469fd47-b58rm             1/1     Running     0          166m
ks-console-54c849bdc9-dfkbf              1/1     Running     0          168m
ks-console-54c849bdc9-z2d5q              1/1     Running     0          168m
ks-controller-manager-569456b4cd-gngm5   1/1     Running     0          170m
ks-docs-6bbdcc9bfb-6jldz                 1/1     Running     0          3h7m
kubesphere-installer-7ph6l               0/1     Completed   1          3h11m
openldap-5c986c5bff-rzqwv                1/1     Running     0          3h25m
redis-76dc4db5dd-lv6kg                   1/1     Running     0          149m
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;安装过程出现的错误&#34;&gt;安装过程出现的错误&lt;/h3&gt;
&lt;p&gt;1.在安装的时提示metrics-server已经安装，导致安装中断；&lt;/p&gt;
&lt;p&gt;解析办法：在kubesphere-installer.yaml的configMap增加配置：metrics_server_enable: False（默认是没有的）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
data:
  ks-config.yaml: |
    kube_apiserver_host: 10.10.5.208:6443
    etcd_tls_enable: True
    etcd_endpoint_ips: 10.10.5.169,10.10.5.183,10.10.5.184
    disableMultiLogin: True
    elk_prefix: logstash
    metrics_server_enable: False
  #  local_registry: 192.168.1.2:5000
kind: ConfigMap
metadata:
  name: kubesphere-config
  namespace: kubesphere-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;增加Ingress配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: kubesphere
  namespace: kubesphere-system
  annotations:
    #kubernetes.io/ingress.class: traefik
    kubernetes.io/ingress.class: nginx
spec:
  rules:
  - host: ks.staplescn.com
    http:
      paths:
      - path:
        backend:
          serviceName: ks-console
          servicePort: 80
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;访问界面：&lt;br&gt;
&lt;img src=&#34;https://lvelvis.github.io/post-images/1588153130667.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
">kubesphere安装使用体验</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://lvelvis.github.io/post/about/"" data-c="
          &lt;blockquote&gt;
&lt;p&gt;欢迎来到我的小站呀，很高兴遇见你！🤝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;关于本站&#34;&gt;🏠 关于本站&lt;/h2&gt;
&lt;h2 id=&#34;博主是谁&#34;&gt;👨‍💻 博主是谁&lt;/h2&gt;
&lt;h2 id=&#34;兴趣爱好&#34;&gt;⛹ 兴趣爱好&lt;/h2&gt;
&lt;h2 id=&#34;联系我呀&#34;&gt;📬 联系我呀&lt;/h2&gt;
">关于</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://lvelvis.github.io/post/kubernetes搭建rook-ceph/"" data-c="
          &lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Rook官网：https://rook.io&lt;br&gt;
Rook是云原生计算基金会(CNCF)的孵化级项目.&lt;br&gt;
Rook是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。&lt;br&gt;
至于CEPH，官网在这：https://ceph.com/&lt;br&gt;
ceph官方提供的helm部署，至今我没成功过，所以转向使用rook提供的方案&lt;br&gt;
有道笔记原文：http://note.youdao.com/noteshare?id=281719f1f0374f787effc90067e0d5ad&amp;amp;sub=0B59EA339D4A4769B55F008D72C1A4C0&lt;/p&gt;
&lt;h3 id=&#34;环境&#34;&gt;环境&lt;/h3&gt;
&lt;p&gt;centos 7.5&lt;br&gt;
kernel 4.18.7-1.el7.elrepo.x86_64&lt;/p&gt;
&lt;p&gt;docker 18.06&lt;/p&gt;
&lt;p&gt;kubernetes v1.12.2&lt;br&gt;
kubeadm部署：&lt;br&gt;
网络: canal&lt;br&gt;
DNS: coredns&lt;br&gt;
集群成员：&lt;br&gt;
192.168.1.1 kube-master&lt;br&gt;
192.168.1.2 kube-node1&lt;br&gt;
192.168.1.3 kube-node2&lt;br&gt;
192.168.1.4 kube-node3&lt;br&gt;
192.168.1.5 kube-node4&lt;/p&gt;
&lt;p&gt;所有node节点准备一块200G的磁盘：/dev/sdb&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;h3 id=&#34;准备工作&#34;&gt;准备工作&lt;/h3&gt;
&lt;p&gt;所有节点开启ip_forward&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;  /etc/sysctl.d/ceph.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;sysctl -p&lt;/p&gt;
&lt;h3 id=&#34;开始部署operator&#34;&gt;开始部署Operator&lt;/h3&gt;
&lt;p&gt;部署Rook Operator&lt;br&gt;
#无另外说明，全部操作都在master操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd $HOME
git clone https://github.com/rook/rook.git

cd rook
cd cluster/examples/kubernetes/ceph
kubectl apply -f operator.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;查看Operator的状态&lt;br&gt;
#执行apply之后稍等一会。&lt;br&gt;
#operator会在集群内的每个主机创建两个pod:rook-discover,rook-ceph-agent&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph-system get pod -o wide&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;给节点打标签&lt;br&gt;
运行ceph-mon的节点打上：ceph-mon=enabled&lt;br&gt;
kubectl label nodes {kube-node1,kube-node2,kube-node3} ceph-mon=enabled&lt;br&gt;
运行ceph-osd的节点，也就是存储节点，打上：ceph-osd=enabled&lt;br&gt;
kubectl label nodes {kube-node1,kube-node2,kube-node3} ceph-osd=enabled&lt;br&gt;
运行ceph-mgr的节点，打上：ceph-mgr=enabled&lt;br&gt;
#mgr只能支持一个节点运行，这是ceph跑k8s里的局限&lt;br&gt;
kubectl label nodes kube-node1 ceph-mgr=enabled&lt;br&gt;
配置cluster.yaml文件&lt;br&gt;
官方配置文件详解：https://rook.io/docs/rook/v0.8/ceph-cluster-crd.html&lt;/p&gt;
&lt;p&gt;文件中有几个地方要注意：&lt;/p&gt;
&lt;p&gt;dataDirHostPath: 这个路径是会在宿主机上生成的，保存的是ceph的相关的配置文件，再重新生成集群的时候要确保这个目录为空，否则mon会无法启动&lt;br&gt;
useAllDevices: 使用所有的设备，建议为false，否则会把宿主机所有可用的磁盘都干掉&lt;br&gt;
useAllNodes：使用所有的node节点，建议为false，肯定不会用k8s集群内的所有node来搭建ceph的&lt;br&gt;
databaseSizeMB和journalSizeMB：当磁盘大于100G的时候，就注释这俩项就行了&lt;br&gt;
本次实验用到的 cluster.yaml 文件内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Namespace
metadata:
  name: rook-ceph
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rook-ceph-cluster
  namespace: rook-ceph
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-ceph-cluster
  namespace: rook-ceph
rules:
- apiGroups: [&amp;quot;&amp;quot;]
  resources: [&amp;quot;configmaps&amp;quot;]
  verbs: [ &amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;, &amp;quot;create&amp;quot;, &amp;quot;update&amp;quot;, &amp;quot;delete&amp;quot; ]
---
# Allow the operator to create resources in this cluster&#39;s namespace
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-ceph-cluster-mgmt
  namespace: rook-ceph
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: rook-ceph-cluster-mgmt
subjects:
- kind: ServiceAccount
  name: rook-ceph-system
  namespace: rook-ceph-system
---
# Allow the pods in this namespace to work with configmaps
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-ceph-cluster
  namespace: rook-ceph
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: rook-ceph-cluster
subjects:
- kind: ServiceAccount
  name: rook-ceph-cluster
  namespace: rook-ceph
---
apiVersion: ceph.rook.io/v1beta1
kind: Cluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    # The container image used to launch the Ceph daemon pods (mon, mgr, osd, mds, rgw).
    # v12 is luminous, v13 is mimic, and v14 is nautilus.
    # RECOMMENDATION: In production, use a specific version tag instead of the general v13 flag, which pulls the latest release and could result in different
    # versions running within the cluster. See tags available at https://hub.docker.com/r/ceph/ceph/tags/.
    image: ceph/ceph:v13
    # Whether to allow unsupported versions of Ceph. Currently only luminous and mimic are supported.
    # After nautilus is released, Rook will be updated to support nautilus.
    # Do not set to true in production.
    allowUnsupported: false
  # The path on the host where configuration files will be persisted. If not specified, a kubernetes emptyDir will be created (not recommended).
  # Important: if you reinstall the cluster, make sure you delete this directory from each host or else the mons will fail to start on the new cluster.
  # In Minikube, the &#39;/data&#39; directory is configured to persist across reboots. Use &amp;quot;/data/rook&amp;quot; in Minikube environment.
  dataDirHostPath: /var/lib/rook
  # The service account under which to run the daemon pods in this cluster if the default account is not sufficient (OSDs)
  serviceAccount: rook-ceph-cluster
  # set the amount of mons to be started
  # count可以定义ceph-mon运行的数量，这里默认三个就行了
  mon:
    count: 3
    allowMultiplePerNode: true
  # enable the ceph dashboard for viewing cluster status
  # 开启ceph资源面板
  dashboard:
    enabled: true
    # serve the dashboard under a subpath (useful when you are accessing the dashboard via a reverse proxy)
    # urlPrefix: /ceph-dashboard
  network:
    # toggle to use hostNetwork
    # 使用宿主机的网络进行通讯
    # 使用宿主机的网络貌似可以让集群外的主机挂载ceph
    # 但是我没试过，有兴趣的兄弟可以试试改成true
    # 反正这里只是集群内用，我就不改了
    hostNetwork: false
  # To control where various services will be scheduled by kubernetes, use the placement configuration sections below.
  # The example under &#39;all&#39; would have all services scheduled on kubernetes nodes labeled with &#39;role=storage-node&#39; and
  # tolerate taints with a key of &#39;storage-node&#39;.
  placement:
#    all:
#      nodeAffinity:
#        requiredDuringSchedulingIgnoredDuringExecution:
#          nodeSelectorTerms:
#          - matchExpressions:
#            - key: role
#              operator: In
#              values:
#              - storage-node
#      podAffinity:
#      podAntiAffinity:
#      tolerations:
#      - key: storage-node
#        operator: Exists
# The above placement information can also be specified for mon, osd, and mgr components
#    mon:
#    osd:
#    mgr:
# nodeAffinity：通过选择标签的方式，可以限制pod被调度到特定的节点上
# 建议限制一下，为了让这几个pod不乱跑
    mon:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: ceph-mon
              operator: In
              values:
              - enabled
    osd:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: ceph-osd
              operator: In
              values:
              - enabled
    mgr:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: ceph-mgr
              operator: In
              values:
              - enabled
  resources:
# The requests and limits set here, allow the mgr pod to use half of one CPU core and 1 gigabyte of memory
#    mgr:
#      limits:
#        cpu: &amp;quot;500m&amp;quot;
#        memory: &amp;quot;1024Mi&amp;quot;
#      requests:
#        cpu: &amp;quot;500m&amp;quot;
#        memory: &amp;quot;1024Mi&amp;quot;
# The above example requests/limits can also be added to the mon and osd components
#    mon:
#    osd:
  storage: # cluster level storage configuration and selection
    useAllNodes: false
    useAllDevices: false
    deviceFilter:
    location:
    config:
      # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.
      # Set the storeType explicitly only if it is required not to use the default.
      # storeType: bluestore
      # databaseSizeMB: &amp;quot;1024&amp;quot; # this value can be removed for environments with normal sized disks (100 GB or larger)
      # journalSizeMB: &amp;quot;1024&amp;quot;  # this value can be removed for environments with normal sized disks (20 GB or larger)
# Cluster level list of directories to use for storage. These values will be set for all nodes that have no `directories` set.
#    directories:
#    - path: /rook/storage-dir
# Individual nodes and their config can be specified as well, but &#39;useAllNodes&#39; above must be set to false. Then, only the named
# nodes below will be used as storage resources.  Each node&#39;s &#39;name&#39; field should match their &#39;kubernetes.io/hostname&#39; label.
#建议磁盘配置方式如下：
#name: 选择一个节点，节点名字为kubernetes.io/hostname的标签，也就是kubectl get nodes看到的名字
#devices: 选择磁盘设置为OSD
# - name: &amp;quot;sdb&amp;quot;:将/dev/sdb设置为osd
    nodes:
    - name: &amp;quot;kube-node1&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;
    - name: &amp;quot;kube-node2&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;
    - name: &amp;quot;kube-node3&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;

#      directories: # specific directories to use for storage can be specified for each node
#      - path: &amp;quot;/rook/storage-dir&amp;quot;
#      resources:
#        limits:
#          cpu: &amp;quot;500m&amp;quot;
#          memory: &amp;quot;1024Mi&amp;quot;
#        requests:
#          cpu: &amp;quot;500m&amp;quot;
#          memory: &amp;quot;1024Mi&amp;quot;
#    - name: &amp;quot;172.17.4.201&amp;quot;
#      devices: # specific devices to use for storage can be specified for each node
#      - name: &amp;quot;sdb&amp;quot;
#      - name: &amp;quot;sdc&amp;quot;
#      config: # configuration can be specified at the node level which overrides the cluster level config
#        storeType: filestore
#    - name: &amp;quot;172.17.4.301&amp;quot;
#      deviceFilter: &amp;quot;^sd.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;开始部署ceph&lt;br&gt;
部署ceph&lt;br&gt;
kubectl apply -f cluster.yaml&lt;br&gt;
cluster会在rook-ceph这个namesapce创建资源&lt;br&gt;
盯着这个namesapce的pod你就会发现，它在按照顺序创建Pod&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph get pod -o wide  -w&lt;/p&gt;
&lt;p&gt;看到所有的pod都Running就行了&lt;br&gt;
注意看一下pod分布的宿主机，跟我们打标签的主机是一致的&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph get pod -o wide&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;切换到其他主机看一下磁盘&lt;/p&gt;
&lt;p&gt;切换到kube-node1&lt;br&gt;
lsblk&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;切换到kube-node3&lt;br&gt;
lsblk&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;配置ceph dashboard&lt;br&gt;
看一眼dashboard在哪个service上&lt;br&gt;
kubectl -n rook-ceph get service&lt;br&gt;
可以看到dashboard监听了8443端口&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;创建个nodeport类型的service以便集群外部访问&lt;br&gt;
kubectl apply -f dashboard-external-https.yaml&lt;/p&gt;
&lt;p&gt;查看一下nodeport在哪个端口&lt;br&gt;
ss -tanl&lt;br&gt;
kubectl -n rook-ceph get service&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;找出Dashboard的登陆账号和密码&lt;br&gt;
MGR_POD=&lt;code&gt;kubectl get pod -n rook-ceph | grep mgr | awk &#39;{print $1}&#39;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph logs $MGR_POD | grep password&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;打开浏览器输入任意一个Node的IP+nodeport端口&lt;br&gt;
这里我的就是：https://192.168.1.2:30290&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;配置ceph为storageclass&lt;br&gt;
官方给了一个样本文件：storageclass.yaml&lt;br&gt;
这个文件使用的是 RBD 块存储&lt;br&gt;
pool创建详解：https://rook.io/docs/rook/v0.8/ceph-pool-crd.html&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: ceph.rook.io/v1beta1
kind: Pool
metadata:
  #这个name就是创建成ceph pool之后的pool名字
  name: replicapool
  namespace: rook-ceph
spec:
  replicated:
    size: 1
  # size 池中数据的副本数,1就是不保存任何副本
  failureDomain: osd
  #  failureDomain：数据块的故障域，
  #  值为host时，每个数据块将放置在不同的主机上
  #  值为osd时，每个数据块将放置在不同的osd上
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: ceph
   # StorageClass的名字，pvc调用时填的名字
provisioner: ceph.rook.io/block
parameters:
  pool: replicapool
  # Specify the namespace of the rook cluster from which to create volumes.
  # If not specified, it will use `rook` as the default namespace of the cluster.
  # This is also the namespace where the cluster will be
  clusterNamespace: rook-ceph
  # Specify the filesystem type of the volume. If not specified, it will use `ext4`.
  fstype: xfs
# 设置回收策略默认为：Retain
reclaimPolicy: Retain
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;创建StorageClass&lt;br&gt;
kubectl apply -f storageclass.yaml&lt;br&gt;
kubectl get storageclasses.storage.k8s.io  -n rook-ceph&lt;br&gt;
kubectl describe storageclasses.storage.k8s.io  -n rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;创建个nginx pod尝试挂载&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; nginx.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nginx-pvc
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: ceph

---
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    app: nginx
  ports: 
  - port: 80
    name: nginx-port
    targetPort: 80
    protocol: TCP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
        volumeMounts:
        - mountPath: /html
          name: http-file
      volumes:
      - name: http-file
        persistentVolumeClaim:
          claimName: nginx-pvc
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;kubectl apply -f nginx.yaml&lt;br&gt;
查看pv,pvc是否创建了&lt;br&gt;
kubectl get pv,pvc&lt;/p&gt;
&lt;p&gt;看一下nginx这个pod也运行了&lt;br&gt;
kubectl get pod&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;删除这个pod,看pv是否还存在&lt;br&gt;
kubectl delete -f nginx.yaml&lt;/p&gt;
&lt;p&gt;kubectl get pv,pvc&lt;br&gt;
可以看到，pod和pvc都已经被删除了，但是pv还在！！！&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;添加新的OSD进入集群&lt;br&gt;
这次我们要把node4添加进集群，先打标签&lt;br&gt;
kubectl label nodes kube-node4 ceph-osd=enabled&lt;br&gt;
重新编辑cluster.yaml文件&lt;br&gt;
原来的基础上添加node4的信息&lt;/p&gt;
&lt;p&gt;cd $HOME/rook/cluster/examples/kubernetes/ceph/&lt;br&gt;
vi cluster.yam&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;apply一下cluster.yaml文件&lt;br&gt;
kubectl apply -f cluster.yaml&lt;/p&gt;
&lt;p&gt;盯着rook-ceph名称空间,集群会自动添加node4进来&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph get pod -o wide -w&lt;br&gt;
kubectl -n rook-ceph get pod -o wide&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;去node4节点看一下磁盘&lt;br&gt;
lsblk&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;再打开dashboard看一眼&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;删除一个节点&lt;br&gt;
去掉node3的标签&lt;br&gt;
kubectl label nodes kube-node3 ceph-osd-&lt;br&gt;
重新编辑cluster.yaml文件&lt;br&gt;
删除node3的信息&lt;/p&gt;
&lt;p&gt;cd $HOME/rook/cluster/examples/kubernetes/ceph/&lt;br&gt;
vi cluster.yam&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
&lt;p&gt;apply一下cluster.yaml文件&lt;br&gt;
kubectl apply -f cluster.yaml&lt;/p&gt;
&lt;p&gt;盯着rook-ceph名称空间&lt;/p&gt;
&lt;p&gt;kubectl -n rook-ceph get pod -o wide -w&lt;br&gt;
kubectl -n rook-ceph get pod -o wide&lt;/p&gt;
&lt;p&gt;最后记得删除宿主机的/var/lib/rook文件夹&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;br&gt;
kubernetes搭建rook-ceph&lt;/p&gt;
">kubernetes搭建rook-ceph</a>
      </div>
      
    </div>
  </div>
</div>
<script>
  // var escape = "[{&#34;content&#34;:&#34;&lt;p&gt;最近又出来个kubesphere的工具用来管理k8s，今天特意来安装体验下；&lt;br&gt;\ngithub地址：https://github.com/pixiake/ks-installer&lt;/p&gt;\n&lt;p&gt;官方使用文档：https://kubesphere.io/docs/advanced-v2.0/zh-CN/installation/all-in-one/&lt;/p&gt;\n&lt;p&gt;先放上安装效果图，UI界面还是很清爽的：&lt;br&gt;\n&lt;img src=\&#34;https://lvelvis.github.io/post-images/1588152934567.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&lt;h3 id=\&#34;当前环境\&#34;&gt;当前环境：&lt;/h3&gt;\n&lt;pre&gt;&lt;code&gt;k8s集群已经安装完成，用kubesphere管理现有的k8s集群；\n\nk8s版本为1.14\n\n系统为centos7.6\n\nkubesphere使用要求：\n\nkubernetes version &amp;gt; 1.13.0\n\nhelm version &amp;gt; 2.10.0\n\na default storage class must be in kubernetes cluster\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;安装完成后默认用户名密码：&lt;/p&gt;\n&lt;p&gt;用户名：admin&lt;/p&gt;\n&lt;p&gt;密码：P@88w0rd&lt;/p&gt;\n&lt;h3 id=\&#34;开始安装\&#34;&gt;开始安装&lt;/h3&gt;\n&lt;p&gt;安装步骤大概记录：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;kubectl create ns kubesphere-system\nkubectl create ns kubesphere-monitoring-system\n\n#访问etcd用到的secret\nkubectl -n kubesphere-monitoring-system create secret generic kube-etcd-client-certs  --from-file=etcd-client-ca.crt=ca.pem  --from-file=etcd-client.crt=etcd-key.pem  --from-file=etcd-client.key=etcd.pem\n\n#管理k8s用到的secret\n\nkubectl -n kubesphere-system create secret generic kubesphere-ca  --from-file=ca.crt=ca.pem --from-file=ca.key=ca-key.pem\n\n#clone好github项目，执行下面的这条命令\n\ncd deploy\nkubectl apply -f kubesphere-installer.yaml\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;执行完上面的命令，可以通过下面的命令，查看安装过程日志&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l job-name=kubesphere-installer -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -f\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;查看安装结果，STATUS跟下面保持一致才说明安装成功&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;[root@ks-allinone deploy]# kubectl get pods -n kubesphere-system\nNAME                                     READY   STATUS      RESTARTS   AGE\nks-account-6db466d8dc-srrwj              1/1     Running     0          149m\nks-apigateway-7d77cb9495-jzmg6           1/1     Running     0          170m\nks-apiserver-f8469fd47-b58rm             1/1     Running     0          166m\nks-console-54c849bdc9-dfkbf              1/1     Running     0          168m\nks-console-54c849bdc9-z2d5q              1/1     Running     0          168m\nks-controller-manager-569456b4cd-gngm5   1/1     Running     0          170m\nks-docs-6bbdcc9bfb-6jldz                 1/1     Running     0          3h7m\nkubesphere-installer-7ph6l               0/1     Completed   1          3h11m\nopenldap-5c986c5bff-rzqwv                1/1     Running     0          3h25m\nredis-76dc4db5dd-lv6kg                   1/1     Running     0          149m\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;安装过程出现的错误\&#34;&gt;安装过程出现的错误&lt;/h3&gt;\n&lt;p&gt;1.在安装的时提示metrics-server已经安装，导致安装中断；&lt;/p&gt;\n&lt;p&gt;解析办法：在kubesphere-installer.yaml的configMap增加配置：metrics_server_enable: False（默认是没有的）&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;apiVersion: v1\ndata:\n  ks-config.yaml: |\n    kube_apiserver_host: 10.10.5.208:6443\n    etcd_tls_enable: True\n    etcd_endpoint_ips: 10.10.5.169,10.10.5.183,10.10.5.184\n    disableMultiLogin: True\n    elk_prefix: logstash\n    metrics_server_enable: False\n  #  local_registry: 192.168.1.2:5000\nkind: ConfigMap\nmetadata:\n  name: kubesphere-config\n  namespace: kubesphere-system\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;增加Ingress配置：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: kubesphere\n  namespace: kubesphere-system\n  annotations:\n    #kubernetes.io/ingress.class: traefik\n    kubernetes.io/ingress.class: nginx\nspec:\n  rules:\n  - host: ks.staplescn.com\n    http:\n      paths:\n      - path:\n        backend:\n          serviceName: ks-console\n          servicePort: 80\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;访问界面：&lt;br&gt;\n&lt;img src=\&#34;https://lvelvis.github.io/post-images/1588153130667.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;kubesphere-an-zhuang-shi-yong-ti-yan&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;kubesphere安装使用体验&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;kubesphere&#34;,&#34;slug&#34;:&#34;BU7sbQs51&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://lvelvis.github.io/tag/BU7sbQs51/&#34;},{&#34;index&#34;:-1,&#34;name&#34;:&#34;k8s&#34;,&#34;slug&#34;:&#34;Q617Y3Kh2&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://lvelvis.github.io/tag/Q617Y3Kh2/&#34;}],&#34;date&#34;:&#34;2020-04-29 17:33:05&#34;,&#34;dateFormat&#34;:&#34;2020-04-29&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://lvelvis.github.io/post/kubesphere-an-zhuang-shi-yong-ti-yan/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:176000,&#34;words&#34;:576,&#34;minutes&#34;:3},&#34;description&#34;:&#34;最近又出来个kubesphere的工具用来管理k8s，今天特意来安装体验下；\ngithub地址：https://github.com/pixiake/ks-installer\n官方使用文档：https://kubesphere.io/doc...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BD%93%E5%89%8D%E7%8E%AF%E5%A2%83\&#34;&gt;当前环境：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BC%80%E5%A7%8B%E5%AE%89%E8%A3%85\&#34;&gt;开始安装&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%E5%87%BA%E7%8E%B0%E7%9A%84%E9%94%99%E8%AF%AF\&#34;&gt;安装过程出现的错误&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;blockquote&gt;\n&lt;p&gt;欢迎来到我的小站呀，很高兴遇见你！🤝&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;h2 id=\&#34;关于本站\&#34;&gt;🏠 关于本站&lt;/h2&gt;\n&lt;h2 id=\&#34;博主是谁\&#34;&gt;👨‍💻 博主是谁&lt;/h2&gt;\n&lt;h2 id=\&#34;兴趣爱好\&#34;&gt;⛹ 兴趣爱好&lt;/h2&gt;\n&lt;h2 id=\&#34;联系我呀\&#34;&gt;📬 联系我呀&lt;/h2&gt;\n&#34;,&#34;fileName&#34;:&#34;about&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;关于&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2019-01-25 19:09:48&#34;,&#34;dateFormat&#34;:&#34;2019-01-25&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://lvelvis.github.io/post/about/&#34;,&#34;hideInList&#34;:true,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:6000,&#34;words&#34;:31,&#34;minutes&#34;:1},&#34;description&#34;:&#34;\n欢迎来到我的小站呀，很高兴遇见你！🤝\n\n🏠 关于本站\n👨‍💻 博主是谁\n⛹ 兴趣爱好\n📬 联系我呀\n...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99\&#34;&gt;🏠 关于本站&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8D%9A%E4%B8%BB%E6%98%AF%E8%B0%81\&#34;&gt;👨‍💻 博主是谁&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD\&#34;&gt;⛹ 兴趣爱好&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%81%94%E7%B3%BB%E6%88%91%E5%91%80\&#34;&gt;📬 联系我呀&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;简介\&#34;&gt;简介&lt;/h3&gt;\n&lt;p&gt;Rook官网：https://rook.io&lt;br&gt;\nRook是云原生计算基金会(CNCF)的孵化级项目.&lt;br&gt;\nRook是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。&lt;br&gt;\n至于CEPH，官网在这：https://ceph.com/&lt;br&gt;\nceph官方提供的helm部署，至今我没成功过，所以转向使用rook提供的方案&lt;br&gt;\n有道笔记原文：http://note.youdao.com/noteshare?id=281719f1f0374f787effc90067e0d5ad&amp;amp;sub=0B59EA339D4A4769B55F008D72C1A4C0&lt;/p&gt;\n&lt;h3 id=\&#34;环境\&#34;&gt;环境&lt;/h3&gt;\n&lt;p&gt;centos 7.5&lt;br&gt;\nkernel 4.18.7-1.el7.elrepo.x86_64&lt;/p&gt;\n&lt;p&gt;docker 18.06&lt;/p&gt;\n&lt;p&gt;kubernetes v1.12.2&lt;br&gt;\nkubeadm部署：&lt;br&gt;\n网络: canal&lt;br&gt;\nDNS: coredns&lt;br&gt;\n集群成员：&lt;br&gt;\n192.168.1.1 kube-master&lt;br&gt;\n192.168.1.2 kube-node1&lt;br&gt;\n192.168.1.3 kube-node2&lt;br&gt;\n192.168.1.4 kube-node3&lt;br&gt;\n192.168.1.5 kube-node4&lt;/p&gt;\n&lt;p&gt;所有node节点准备一块200G的磁盘：/dev/sdb&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;h3 id=\&#34;准备工作\&#34;&gt;准备工作&lt;/h3&gt;\n&lt;p&gt;所有节点开启ip_forward&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;  /etc/sysctl.d/ceph.conf\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;sysctl -p&lt;/p&gt;\n&lt;h3 id=\&#34;开始部署operator\&#34;&gt;开始部署Operator&lt;/h3&gt;\n&lt;p&gt;部署Rook Operator&lt;br&gt;\n#无另外说明，全部操作都在master操作&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;cd $HOME\ngit clone https://github.com/rook/rook.git\n\ncd rook\ncd cluster/examples/kubernetes/ceph\nkubectl apply -f operator.yaml\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;kubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;查看Operator的状态&lt;br&gt;\n#执行apply之后稍等一会。&lt;br&gt;\n#operator会在集群内的每个主机创建两个pod:rook-discover,rook-ceph-agent&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph-system get pod -o wide&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;给节点打标签&lt;br&gt;\n运行ceph-mon的节点打上：ceph-mon=enabled&lt;br&gt;\nkubectl label nodes {kube-node1,kube-node2,kube-node3} ceph-mon=enabled&lt;br&gt;\n运行ceph-osd的节点，也就是存储节点，打上：ceph-osd=enabled&lt;br&gt;\nkubectl label nodes {kube-node1,kube-node2,kube-node3} ceph-osd=enabled&lt;br&gt;\n运行ceph-mgr的节点，打上：ceph-mgr=enabled&lt;br&gt;\n#mgr只能支持一个节点运行，这是ceph跑k8s里的局限&lt;br&gt;\nkubectl label nodes kube-node1 ceph-mgr=enabled&lt;br&gt;\n配置cluster.yaml文件&lt;br&gt;\n官方配置文件详解：https://rook.io/docs/rook/v0.8/ceph-cluster-crd.html&lt;/p&gt;\n&lt;p&gt;文件中有几个地方要注意：&lt;/p&gt;\n&lt;p&gt;dataDirHostPath: 这个路径是会在宿主机上生成的，保存的是ceph的相关的配置文件，再重新生成集群的时候要确保这个目录为空，否则mon会无法启动&lt;br&gt;\nuseAllDevices: 使用所有的设备，建议为false，否则会把宿主机所有可用的磁盘都干掉&lt;br&gt;\nuseAllNodes：使用所有的node节点，建议为false，肯定不会用k8s集群内的所有node来搭建ceph的&lt;br&gt;\ndatabaseSizeMB和journalSizeMB：当磁盘大于100G的时候，就注释这俩项就行了&lt;br&gt;\n本次实验用到的 cluster.yaml 文件内容如下：&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;apiVersion: v1\nkind: Namespace\nmetadata:\n  name: rook-ceph\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: rook-ceph-cluster\n  namespace: rook-ceph\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: rook-ceph-cluster\n  namespace: rook-ceph\nrules:\n- apiGroups: [&amp;quot;&amp;quot;]\n  resources: [&amp;quot;configmaps&amp;quot;]\n  verbs: [ &amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;, &amp;quot;create&amp;quot;, &amp;quot;update&amp;quot;, &amp;quot;delete&amp;quot; ]\n---\n# Allow the operator to create resources in this cluster&#39;s namespace\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: rook-ceph-cluster-mgmt\n  namespace: rook-ceph\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: rook-ceph-cluster-mgmt\nsubjects:\n- kind: ServiceAccount\n  name: rook-ceph-system\n  namespace: rook-ceph-system\n---\n# Allow the pods in this namespace to work with configmaps\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: rook-ceph-cluster\n  namespace: rook-ceph\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: rook-ceph-cluster\nsubjects:\n- kind: ServiceAccount\n  name: rook-ceph-cluster\n  namespace: rook-ceph\n---\napiVersion: ceph.rook.io/v1beta1\nkind: Cluster\nmetadata:\n  name: rook-ceph\n  namespace: rook-ceph\nspec:\n  cephVersion:\n    # The container image used to launch the Ceph daemon pods (mon, mgr, osd, mds, rgw).\n    # v12 is luminous, v13 is mimic, and v14 is nautilus.\n    # RECOMMENDATION: In production, use a specific version tag instead of the general v13 flag, which pulls the latest release and could result in different\n    # versions running within the cluster. See tags available at https://hub.docker.com/r/ceph/ceph/tags/.\n    image: ceph/ceph:v13\n    # Whether to allow unsupported versions of Ceph. Currently only luminous and mimic are supported.\n    # After nautilus is released, Rook will be updated to support nautilus.\n    # Do not set to true in production.\n    allowUnsupported: false\n  # The path on the host where configuration files will be persisted. If not specified, a kubernetes emptyDir will be created (not recommended).\n  # Important: if you reinstall the cluster, make sure you delete this directory from each host or else the mons will fail to start on the new cluster.\n  # In Minikube, the &#39;/data&#39; directory is configured to persist across reboots. Use &amp;quot;/data/rook&amp;quot; in Minikube environment.\n  dataDirHostPath: /var/lib/rook\n  # The service account under which to run the daemon pods in this cluster if the default account is not sufficient (OSDs)\n  serviceAccount: rook-ceph-cluster\n  # set the amount of mons to be started\n  # count可以定义ceph-mon运行的数量，这里默认三个就行了\n  mon:\n    count: 3\n    allowMultiplePerNode: true\n  # enable the ceph dashboard for viewing cluster status\n  # 开启ceph资源面板\n  dashboard:\n    enabled: true\n    # serve the dashboard under a subpath (useful when you are accessing the dashboard via a reverse proxy)\n    # urlPrefix: /ceph-dashboard\n  network:\n    # toggle to use hostNetwork\n    # 使用宿主机的网络进行通讯\n    # 使用宿主机的网络貌似可以让集群外的主机挂载ceph\n    # 但是我没试过，有兴趣的兄弟可以试试改成true\n    # 反正这里只是集群内用，我就不改了\n    hostNetwork: false\n  # To control where various services will be scheduled by kubernetes, use the placement configuration sections below.\n  # The example under &#39;all&#39; would have all services scheduled on kubernetes nodes labeled with &#39;role=storage-node&#39; and\n  # tolerate taints with a key of &#39;storage-node&#39;.\n  placement:\n#    all:\n#      nodeAffinity:\n#        requiredDuringSchedulingIgnoredDuringExecution:\n#          nodeSelectorTerms:\n#          - matchExpressions:\n#            - key: role\n#              operator: In\n#              values:\n#              - storage-node\n#      podAffinity:\n#      podAntiAffinity:\n#      tolerations:\n#      - key: storage-node\n#        operator: Exists\n# The above placement information can also be specified for mon, osd, and mgr components\n#    mon:\n#    osd:\n#    mgr:\n# nodeAffinity：通过选择标签的方式，可以限制pod被调度到特定的节点上\n# 建议限制一下，为了让这几个pod不乱跑\n    mon:\n      nodeAffinity:\n        requiredDuringSchedulingIgnoredDuringExecution:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: ceph-mon\n              operator: In\n              values:\n              - enabled\n    osd:\n      nodeAffinity:\n        requiredDuringSchedulingIgnoredDuringExecution:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: ceph-osd\n              operator: In\n              values:\n              - enabled\n    mgr:\n      nodeAffinity:\n        requiredDuringSchedulingIgnoredDuringExecution:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: ceph-mgr\n              operator: In\n              values:\n              - enabled\n  resources:\n# The requests and limits set here, allow the mgr pod to use half of one CPU core and 1 gigabyte of memory\n#    mgr:\n#      limits:\n#        cpu: &amp;quot;500m&amp;quot;\n#        memory: &amp;quot;1024Mi&amp;quot;\n#      requests:\n#        cpu: &amp;quot;500m&amp;quot;\n#        memory: &amp;quot;1024Mi&amp;quot;\n# The above example requests/limits can also be added to the mon and osd components\n#    mon:\n#    osd:\n  storage: # cluster level storage configuration and selection\n    useAllNodes: false\n    useAllDevices: false\n    deviceFilter:\n    location:\n    config:\n      # The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories.\n      # Set the storeType explicitly only if it is required not to use the default.\n      # storeType: bluestore\n      # databaseSizeMB: &amp;quot;1024&amp;quot; # this value can be removed for environments with normal sized disks (100 GB or larger)\n      # journalSizeMB: &amp;quot;1024&amp;quot;  # this value can be removed for environments with normal sized disks (20 GB or larger)\n# Cluster level list of directories to use for storage. These values will be set for all nodes that have no `directories` set.\n#    directories:\n#    - path: /rook/storage-dir\n# Individual nodes and their config can be specified as well, but &#39;useAllNodes&#39; above must be set to false. Then, only the named\n# nodes below will be used as storage resources.  Each node&#39;s &#39;name&#39; field should match their &#39;kubernetes.io/hostname&#39; label.\n#建议磁盘配置方式如下：\n#name: 选择一个节点，节点名字为kubernetes.io/hostname的标签，也就是kubectl get nodes看到的名字\n#devices: 选择磁盘设置为OSD\n# - name: &amp;quot;sdb&amp;quot;:将/dev/sdb设置为osd\n    nodes:\n    - name: &amp;quot;kube-node1&amp;quot;\n      devices:\n      - name: &amp;quot;sdb&amp;quot;\n    - name: &amp;quot;kube-node2&amp;quot;\n      devices:\n      - name: &amp;quot;sdb&amp;quot;\n    - name: &amp;quot;kube-node3&amp;quot;\n      devices:\n      - name: &amp;quot;sdb&amp;quot;\n\n#      directories: # specific directories to use for storage can be specified for each node\n#      - path: &amp;quot;/rook/storage-dir&amp;quot;\n#      resources:\n#        limits:\n#          cpu: &amp;quot;500m&amp;quot;\n#          memory: &amp;quot;1024Mi&amp;quot;\n#        requests:\n#          cpu: &amp;quot;500m&amp;quot;\n#          memory: &amp;quot;1024Mi&amp;quot;\n#    - name: &amp;quot;172.17.4.201&amp;quot;\n#      devices: # specific devices to use for storage can be specified for each node\n#      - name: &amp;quot;sdb&amp;quot;\n#      - name: &amp;quot;sdc&amp;quot;\n#      config: # configuration can be specified at the node level which overrides the cluster level config\n#        storeType: filestore\n#    - name: &amp;quot;172.17.4.301&amp;quot;\n#      deviceFilter: &amp;quot;^sd.&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;开始部署ceph&lt;br&gt;\n部署ceph&lt;br&gt;\nkubectl apply -f cluster.yaml&lt;br&gt;\ncluster会在rook-ceph这个namesapce创建资源&lt;br&gt;\n盯着这个namesapce的pod你就会发现，它在按照顺序创建Pod&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph get pod -o wide  -w&lt;/p&gt;\n&lt;p&gt;看到所有的pod都Running就行了&lt;br&gt;\n注意看一下pod分布的宿主机，跟我们打标签的主机是一致的&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph get pod -o wide&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;切换到其他主机看一下磁盘&lt;/p&gt;\n&lt;p&gt;切换到kube-node1&lt;br&gt;\nlsblk&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;切换到kube-node3&lt;br&gt;\nlsblk&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;配置ceph dashboard&lt;br&gt;\n看一眼dashboard在哪个service上&lt;br&gt;\nkubectl -n rook-ceph get service&lt;br&gt;\n可以看到dashboard监听了8443端口&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;创建个nodeport类型的service以便集群外部访问&lt;br&gt;\nkubectl apply -f dashboard-external-https.yaml&lt;/p&gt;\n&lt;p&gt;查看一下nodeport在哪个端口&lt;br&gt;\nss -tanl&lt;br&gt;\nkubectl -n rook-ceph get service&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;找出Dashboard的登陆账号和密码&lt;br&gt;\nMGR_POD=&lt;code&gt;kubectl get pod -n rook-ceph | grep mgr | awk &#39;{print $1}&#39;&lt;/code&gt;&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph logs $MGR_POD | grep password&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;打开浏览器输入任意一个Node的IP+nodeport端口&lt;br&gt;\n这里我的就是：https://192.168.1.2:30290&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;配置ceph为storageclass&lt;br&gt;\n官方给了一个样本文件：storageclass.yaml&lt;br&gt;\n这个文件使用的是 RBD 块存储&lt;br&gt;\npool创建详解：https://rook.io/docs/rook/v0.8/ceph-pool-crd.html&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;apiVersion: ceph.rook.io/v1beta1\nkind: Pool\nmetadata:\n  #这个name就是创建成ceph pool之后的pool名字\n  name: replicapool\n  namespace: rook-ceph\nspec:\n  replicated:\n    size: 1\n  # size 池中数据的副本数,1就是不保存任何副本\n  failureDomain: osd\n  #  failureDomain：数据块的故障域，\n  #  值为host时，每个数据块将放置在不同的主机上\n  #  值为osd时，每个数据块将放置在不同的osd上\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n   name: ceph\n   # StorageClass的名字，pvc调用时填的名字\nprovisioner: ceph.rook.io/block\nparameters:\n  pool: replicapool\n  # Specify the namespace of the rook cluster from which to create volumes.\n  # If not specified, it will use `rook` as the default namespace of the cluster.\n  # This is also the namespace where the cluster will be\n  clusterNamespace: rook-ceph\n  # Specify the filesystem type of the volume. If not specified, it will use `ext4`.\n  fstype: xfs\n# 设置回收策略默认为：Retain\nreclaimPolicy: Retain\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;创建StorageClass&lt;br&gt;\nkubectl apply -f storageclass.yaml&lt;br&gt;\nkubectl get storageclasses.storage.k8s.io  -n rook-ceph&lt;br&gt;\nkubectl describe storageclasses.storage.k8s.io  -n rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;创建个nginx pod尝试挂载&lt;/p&gt;\n&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; nginx.yaml\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nginx-pvc\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n  storageClassName: ceph\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  selector:\n    app: nginx\n  ports: \n  - port: 80\n    name: nginx-port\n    targetPort: 80\n    protocol: TCP\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      name: nginx\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /html\n          name: http-file\n      volumes:\n      - name: http-file\n        persistentVolumeClaim:\n          claimName: nginx-pvc\nEOF\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;kubectl apply -f nginx.yaml&lt;br&gt;\n查看pv,pvc是否创建了&lt;br&gt;\nkubectl get pv,pvc&lt;/p&gt;\n&lt;p&gt;看一下nginx这个pod也运行了&lt;br&gt;\nkubectl get pod&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;删除这个pod,看pv是否还存在&lt;br&gt;\nkubectl delete -f nginx.yaml&lt;/p&gt;\n&lt;p&gt;kubectl get pv,pvc&lt;br&gt;\n可以看到，pod和pvc都已经被删除了，但是pv还在！！！&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;添加新的OSD进入集群&lt;br&gt;\n这次我们要把node4添加进集群，先打标签&lt;br&gt;\nkubectl label nodes kube-node4 ceph-osd=enabled&lt;br&gt;\n重新编辑cluster.yaml文件&lt;br&gt;\n原来的基础上添加node4的信息&lt;/p&gt;\n&lt;p&gt;cd $HOME/rook/cluster/examples/kubernetes/ceph/&lt;br&gt;\nvi cluster.yam&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;apply一下cluster.yaml文件&lt;br&gt;\nkubectl apply -f cluster.yaml&lt;/p&gt;\n&lt;p&gt;盯着rook-ceph名称空间,集群会自动添加node4进来&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph get pod -o wide -w&lt;br&gt;\nkubectl -n rook-ceph get pod -o wide&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;去node4节点看一下磁盘&lt;br&gt;\nlsblk&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;再打开dashboard看一眼&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;删除一个节点&lt;br&gt;\n去掉node3的标签&lt;br&gt;\nkubectl label nodes kube-node3 ceph-osd-&lt;br&gt;\n重新编辑cluster.yaml文件&lt;br&gt;\n删除node3的信息&lt;/p&gt;\n&lt;p&gt;cd $HOME/rook/cluster/examples/kubernetes/ceph/&lt;br&gt;\nvi cluster.yam&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&lt;p&gt;apply一下cluster.yaml文件&lt;br&gt;\nkubectl apply -f cluster.yaml&lt;/p&gt;\n&lt;p&gt;盯着rook-ceph名称空间&lt;/p&gt;\n&lt;p&gt;kubectl -n rook-ceph get pod -o wide -w&lt;br&gt;\nkubectl -n rook-ceph get pod -o wide&lt;/p&gt;\n&lt;p&gt;最后记得删除宿主机的/var/lib/rook文件夹&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;br&gt;\nkubernetes搭建rook-ceph&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;kubernetes搭建rook-ceph&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;kubernetes搭建rook-ceph&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;k8s&#34;,&#34;slug&#34;:&#34;Q617Y3Kh2&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://lvelvis.github.io/tag/Q617Y3Kh2/&#34;},{&#34;name&#34;:&#34;rook-ceph&#34;,&#34;slug&#34;:&#34;hu0mNDfuy&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://lvelvis.github.io/tag/hu0mNDfuy/&#34;},{&#34;name&#34;:&#34;ceph&#34;,&#34;slug&#34;:&#34;MkN4-Vurh-&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://lvelvis.github.io/tag/MkN4-Vurh-/&#34;}],&#34;date&#34;:&#34;2018-12-12 00:00:00&#34;,&#34;dateFormat&#34;:&#34;2018-12-12&#34;,&#34;feature&#34;:&#34;https://lvelvis.github.io/post-images/kubernetes搭建rook-ceph.png&#34;,&#34;link&#34;:&#34;https://lvelvis.github.io/post/kubernetes搭建rook-ceph/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;14 min read&#34;,&#34;time&#34;:827000,&#34;words&#34;:2695,&#34;minutes&#34;:14},&#34;description&#34;:&#34;简介\nRook官网：https://rook.io\nRook是云原生计算基金会(CNCF)的孵化级项目.\nRook是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。\n至于CEPH...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%AE%80%E4%BB%8B\&#34;&gt;简介&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%8E%AF%E5%A2%83\&#34;&gt;环境&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C\&#34;&gt;准备工作&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2operator\&#34;&gt;开始部署Operator&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;}]";
  // var json = escape.substr(1, escape.length - 2);
  // var datas = json.split(',');
  // for (let i=0; i < datas.length; i++) {
  //   let item = datas[i];
  //   let attrs = item.split('34;:&#34')
  //   debugger
  //   console.log(datas[i])
  // }
  let escapeMap = new Map();
  escapeMap.set('&#34;', '"');
  escapeMap.set('&gt;', '>');
  escapeMap.set('&#39;', "'");
  escapeMap.set('&lt;', '<');
  escapeMap.set('&quot;', '"');
  escapeMap.set('&amp;', '&');
</script> -->

<script src="/media/js/mouse/peace.js"></script>


<script src=" /media/js/cool.js"></script>


</html>